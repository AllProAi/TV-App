<!-- Generated by SpecStory -->

# Intelligent Viewing Experience Enhancements (2025-05-17 00:18:06)

_**User**_

Enhanced Intelligence
Add content recognition to automatically identify shows/movies
Implement scene-based context (understand what's happening on screen)
Create personalized recommendations based on viewing/question history
Multi-device Experience
Add shared viewing with synchronized playback
Enable collaborative Q&A where multiple mobile devices can interact
Implement "send to mobile" for saving interesting information
Technical Showcase
Optimize subtitle processing for near real-time display
Add local wake word detection on mobile to reduce latency
Implement adaptive streaming quality based on connection speed\

---

_**Assistant**_



---

Let me explore the project structure to better understand the MemoryStream TV app.

---

<details>
            <summary>Listed current directory â€¢ **13** results</summary>
        
| Name |
|-------|
| ğŸ“ `.git` |
| ğŸ“„ `2-handoff.md` |
| ğŸ“„ `README.md` |
| ğŸ“„ `package.json` |
| ğŸ“„ `dev.js` |
| ğŸ“„ `build.js` |
| ğŸ“ `docs` |
| ğŸ“ `mobile-app` |
| ğŸ“ `tv-app` |
| ğŸ“ `backend` |
| ğŸ“ `.cursor` |
| ğŸ“„ `.cursorindexingignore` |
| ğŸ“ `.specstory` |

</details>

---

I'll examine the README to understand the project's structure and purpose.

---

Read file: README.md

---

Now I'll look at the tv-app structure to understand how it's organized.

---

<details>
            <summary>Listed directory tv-app â€¢ **4** results</summary>
        
| Name |
|-------|
| ğŸ“„ `webpack.config.js` |
| ğŸ“ `src` |
| ğŸ“ `public` |
| ğŸ“„ `package.json` |

</details>

---

Let's examine the tv-app source code:

---

<details>
            <summary>Listed directory tv-app/src â€¢ **3** results</summary>
        
| Name |
|-------|
| ğŸ“ `styles` |
| ğŸ“ `components` |
| ğŸ“„ `index.js` |

</details>

---

Let's look at the mobile app structure:

---

<details>
            <summary>Listed directory mobile-app â€¢ **4** results</summary>
        
| Name |
|-------|
| ğŸ“„ `package.json` |
| ğŸ“„ `webpack.config.js` |
| ğŸ“ `public` |
| ğŸ“ `src` |

</details>

---

Now let's look at the backend structure:

---

<details>
            <summary>Listed directory backend â€¢ **2** results</summary>
        
| Name |
|-------|
| ğŸ“ `src` |
| ğŸ“„ `package.json` |

</details>

---

Let's check the backend source code:

---

<details>
            <summary>Listed directory backend/src â€¢ **2** results</summary>
        
| Name |
|-------|
| ğŸ“„ `index.js` |
| ğŸ“ `services` |

</details>

---

Let's see what services are implemented in the backend:

---

<details>
            <summary>Listed directory backend/src/services â€¢ **3** results</summary>
        
| Name |
|-------|
| ğŸ“„ `sessionService.js` |
| ğŸ“„ `whisperService.js` |
| ğŸ“„ `gptService.js` |

</details>

---

Now let's look at the components in the TV app:

---

<details>
            <summary>Listed directory tv-app/src/components â€¢ **5** results</summary>
        
| Name |
|-------|
| ğŸ“„ `AIAssistant.js` |
| ğŸ“„ `ConnectionManager.js` |
| ğŸ“„ `RemoteNavigation.js` |
| ğŸ“„ `SubtitleManager.js` |
| ğŸ“„ `VideoPlayer.js` |

</details>

---

Let's check the mobile app components:

---

<details>
            <summary>Listed directory mobile-app/src â€¢ **4** results</summary>
        
| Name |
|-------|
| ğŸ“„ `index.js` |
| ğŸ“„ `service-worker.js` |
| ğŸ“ `components` |
| ğŸ“ `styles` |

</details>

---

<details>
            <summary>Listed directory mobile-app/src/components â€¢ **5** results</summary>
        
| Name |
|-------|
| ğŸ“„ `ConnectionManager.js` |
| ğŸ“„ `ChatInterface.js` |
| ğŸ“„ `VoiceRecorder.js` |
| ğŸ“„ `RemoteControl.js` |
| ğŸ“„ `QRCodeScanner.js` |

</details>

---

Based on my exploration of the project, I'll create a comprehensive implementation plan for the requested features:

# Implementation Plan for MemoryStream Enhancements

## 1. Enhanced Intelligence

### Content Recognition System
1. Integrate with TMDB/IMDB API in the backend to identify content based on metadata and dialog
2. Add a new `ContentRecognitionService.js` to the backend:

---

```diff
- 
+ const axios = require('axios');
+ 
+ /**
+  * Service for recognizing TV shows and movies based on dialogue and metadata
+  */
+ class ContentRecognitionService {
+   constructor(apiKey) {
+     this.tmdbApiKey = apiKey || process.env.TMDB_API_KEY;
+     this.baseUrl = 'https://api.themoviedb.org/3';
+   }
+ 
+   /**
+    * Identify content based on dialogue and metadata
+    * @param {string} dialogue - Transcribed dialogue from the content
+    * @param {Object} metadata - Any available metadata (title, duration, etc.)
+    * @returns {Promise<Object>} Content information
+    */
+   async identifyContent(dialogue, metadata = {}) {
+     try {
+       // First try to match based on metadata if available
+       if (metadata.title) {
+         const metadataResults = await this.searchByTitle(metadata.title);
+         if (metadataResults.length > 0) {
+           return this.getContentDetails(metadataResults[0]);
+         }
+       }
+ 
+       // If no metadata match, try dialogue-based identification
+       // Extract potential show names, character names, and distinctive phrases
+       const potentialTitles = this.extractPotentialTitles(dialogue);
+       const results = [];
+ 
+       for (const title of potentialTitles) {
+         const searchResults = await this.searchByTitle(title);
+         results.push(...searchResults);
+       }
+ 
+       // Score and rank results
+       const scoredResults = this.scoreResults(results, dialogue, metadata);
+       
+       if (scoredResults.length > 0) {
+         return this.getContentDetails(scoredResults[0]);
+       }
+ 
+       return null;
+     } catch (error) {
+       console.error('Error identifying content:', error);
+       return null;
+     }
+   }
+ 
+   /**
+    * Extract potential show or movie titles from dialogue
+    * @param {string} dialogue - Transcribed dialogue
+    * @returns {Array<string>} Potential titles
+    */
+   extractPotentialTitles(dialogue) {
+     // This is a simplified implementation
+     // In a production app, we would use NER models or more sophisticated methods
+     const sentences = dialogue.split(/[.!?]+/);
+     const potentialTitles = [];
+     
+     // Look for quoted text that might be titles
+     const quotedText = dialogue.match(/"([^"]*)"/g) || [];
+     potentialTitles.push(...quotedText.map(t => t.replace(/"/g, '')));
+     
+     // Look for capitalized phrases that might be titles
+     const capitalizedPhrases = dialogue.match(/\b([A-Z][a-z]+\s){1,4}[A-Z][a-z]+\b/g) || [];
+     potentialTitles.push(...capitalizedPhrases);
+     
+     return [...new Set(potentialTitles)]; // Remove duplicates
+   }
+ 
+   /**
+    * Search TMDB by title
+    * @param {string} title - Title to search for
+    * @returns {Promise<Array>} Search results
+    */
+   async searchByTitle(title) {
+     try {
+       const response = await axios.get(`${this.baseUrl}/search/multi`, {
+         params: {
+           api_key: this.tmdbApiKey,
+           query: title,
+           include_adult: false
+         }
+       });
+       
+       return response.data.results || [];
+     } catch (error) {
+       console.error('Error searching by title:', error);
+       return [];
+     }
+   }
+ 
+   /**
+    * Get detailed information about content
+    * @param {Object} item - Basic content item
+    * @returns {Promise<Object>} Detailed content information
+    */
+   async getContentDetails(item) {
+     try {
+       const type = item.media_type === 'movie' ? 'movie' : 'tv';
+       const response = await axios.get(`${this.baseUrl}/${type}/${item.id}`, {
+         params: {
+           api_key: this.tmdbApiKey,
+           append_to_response: 'credits,keywords,videos'
+         }
+       });
+       
+       return {
+         id: item.id,
+         type: type,
+         title: type === 'movie' ? response.data.title : response.data.name,
+         overview: response.data.overview,
+         poster: response.data.poster_path ? 
+           `https://image.tmdb.org/t/p/w500${response.data.poster_path}` : null,
+         backdrop: response.data.backdrop_path ? 
+           `https://image.tmdb.org/t/p/original${response.data.backdrop_path}` : null,
+         year: type === 'movie' ? 
+           (response.data.release_date ? response.data.release_date.split('-')[0] : null) : 
+           (response.data.first_air_date ? response.data.first_air_date.split('-')[0] : null),
+         cast: response.data.credits.cast.slice(0, 10).map(actor => ({
+           name: actor.name,
+           character: actor.character,
+           profile: actor.profile_path ? `https://image.tmdb.org/t/p/w185${actor.profile_path}` : null
+         })),
+         genres: response.data.genres.map(g => g.name),
+         keywords: response.data.keywords.keywords || response.data.keywords.results || []
+       };
+     } catch (error) {
+       console.error('Error getting content details:', error);
+       return null;
+     }
+   }
+ 
+   /**
+    * Score and rank results based on relevance to dialogue and metadata
+    * @param {Array} results - Search results
+    * @param {string} dialogue - Transcribed dialogue
+    * @param {Object} metadata - Any available metadata
+    * @returns {Array} Scored and ranked results
+    */
+   scoreResults(results, dialogue, metadata) {
+     return results
+       .map(result => {
+         let score = 0;
+         
+         // Score based on title match if metadata is available
+         if (metadata.title) {
+           const resultTitle = result.title || result.name || '';
+           const titleSimilarity = this.calculateSimilarity(resultTitle.toLowerCase(), metadata.title.toLowerCase());
+           score += titleSimilarity * 3; // Weighted more heavily
+         }
+         
+         // Score based on overview match with dialogue
+         const overview = result.overview || '';
+         if (overview && dialogue) {
+           const dialogueWords = new Set(dialogue.toLowerCase().split(/\s+/));
+           const overviewWords = overview.toLowerCase().split(/\s+/);
+           
+           const matchingWords = overviewWords.filter(word => dialogueWords.has(word)).length;
+           score += matchingWords / overviewWords.length;
+         }
+         
+         return { ...result, score };
+       })
+       .filter(result => result.score > 0)
+       .sort((a, b) => b.score - a.score);
+   }
+   
+   /**
+    * Calculate text similarity (simplified version)
+    * @param {string} str1 - First string
+    * @param {string} str2 - Second string
+    * @returns {number} Similarity score (0-1)
+    */
+   calculateSimilarity(str1, str2) {
+     // Simple implementation - would use more sophisticated methods in production
+     const words1 = str1.split(/\s+/);
+     const words2 = str2.split(/\s+/);
+     
+     const intersection = words1.filter(word => words2.includes(word)).length;
+     const union = new Set([...words1, ...words2]).size;
+     
+     return intersection / union;
+   }
+ }
+ 
+ module.exports = ContentRecognitionService; 
```

---

### Scene-based Context Analysis
Now, let's create a service for scene-based context understanding:

---

```diff
- 
+ const { OpenAI } = require('openai');
+ 
+ /**
+  * Service for analyzing scenes in video content using AI vision models
+  */
+ class SceneAnalysisService {
+   constructor(apiKey) {
+     this.openai = new OpenAI({
+       apiKey: apiKey || process.env.OPENAI_API_KEY
+     });
+     
+     // Cache to store recent frame analyses to avoid repeated processing
+     this.analysisCache = new Map();
+     // Maximum cache size
+     this.maxCacheSize = 50;
+   }
+ 
+   /**
+    * Analyze a scene from a video frame
+    * @param {string} frameBase64 - Base64-encoded image of the current video frame
+    * @param {string} dialogue - Recent dialogue for context
+    * @returns {Promise<Object>} Scene analysis results
+    */
+   async analyzeScene(frameBase64, dialogue = '') {
+     try {
+       // Generate a cache key based on image hash (simplified here)
+       const cacheKey = this.generateCacheKey(frameBase64);
+       
+       // Check if we have a cached analysis
+       if (this.analysisCache.has(cacheKey)) {
+         return this.analysisCache.get(cacheKey);
+       }
+       
+       // Prepare the prompt for the vision model
+       const messages = [
+         {
+           role: "system",
+           content: `You are a scene analysis AI for a TV assistant app. 
+           Analyze the given frame and provide details about what's happening in the scene.
+           If dialogue is provided, use it for additional context.
+           Focus on: main characters present, their emotions, actions, setting, and significant objects.
+           Structure your response as JSON with these keys: characters, setting, action, mood, objects, relationships.`
+         },
+         {
+           role: "user",
+           content: [
+             { type: "text", text: dialogue ? `Recent dialogue: "${dialogue}"` : "Analyze this scene:" },
+             {
+               type: "image_url",
+               image_url: {
+                 url: `data:image/jpeg;base64,${frameBase64}`
+               }
+             }
+           ]
+         }
+       ];
+ 
+       // Call the OpenAI Vision model
+       const response = await this.openai.chat.completions.create({
+         model: "gpt-4-vision-preview",
+         messages: messages,
+         max_tokens: 1000,
+         response_format: { type: "json_object" }
+       });
+ 
+       // Parse the response
+       let analysis;
+       try {
+         analysis = JSON.parse(response.choices[0].message.content);
+       } catch (parseError) {
+         // Fallback if JSON parsing fails
+         analysis = {
+           raw: response.choices[0].message.content,
+           characters: [],
+           setting: "",
+           action: "",
+           mood: "",
+           objects: [],
+           relationships: []
+         };
+       }
+ 
+       // Add timestamp for cache management
+       analysis.timestamp = Date.now();
+       
+       // Cache the result
+       this.analysisCache.set(cacheKey, analysis);
+       
+       // Clean cache if it exceeds maximum size
+       if (this.analysisCache.size > this.maxCacheSize) {
+         this.cleanCache();
+       }
+       
+       return analysis;
+     } catch (error) {
+       console.error('Error analyzing scene:', error);
+       return {
+         error: 'Failed to analyze scene',
+         characters: [],
+         setting: "",
+         action: "",
+         mood: "",
+         objects: [],
+         relationships: []
+       };
+     }
+   }
+ 
+   /**
+    * Generate a simple cache key from frame data
+    * @param {string} frameBase64 - Base64-encoded image
+    * @returns {string} Cache key
+    */
+   generateCacheKey(frameBase64) {
+     // Simple cache key generation - in production would use proper image hashing
+     const sampleSize = 100;
+     const startPos = Math.floor(frameBase64.length / 2);
+     return frameBase64.substr(startPos, sampleSize);
+   }
+ 
+   /**
+    * Clean the analysis cache by removing oldest entries
+    */
+   cleanCache() {
+     // Convert cache to array, sort by timestamp, and keep only newest entries
+     const entries = [...this.analysisCache.entries()];
+     entries.sort((a, b) => b[1].timestamp - a[1].timestamp);
+     
+     // Keep only the newest entries up to maxCacheSize/2
+     this.analysisCache = new Map(entries.slice(0, Math.floor(this.maxCacheSize / 2)));
+   }
+ 
+   /**
+    * Extract key entities from scene analysis
+    * @param {Object} analysis - Scene analysis
+    * @returns {Object} Key entities and concepts
+    */
+   extractKeyEntities(analysis) {
+     // Extract important entities for context tracking
+     const entities = {
+       characters: analysis.characters || [],
+       locations: [analysis.setting].filter(Boolean),
+       objects: analysis.objects || [],
+       concepts: [analysis.mood, analysis.action].filter(Boolean)
+     };
+     
+     return entities;
+   }
+   
+   /**
+    * Get scene context over time by analyzing multiple frames
+    * @param {Array<Object>} frameAnalyses - Array of frame analyses
+    * @returns {Object} Aggregated scene context
+    */
+   aggregateSceneContext(frameAnalyses) {
+     // Combine multiple frame analyses to get a more complete scene understanding
+     const characters = new Set();
+     const locations = new Set();
+     const objects = new Set();
+     const concepts = new Set();
+     
+     frameAnalyses.forEach(analysis => {
+       const entities = this.extractKeyEntities(analysis);
+       
+       entities.characters.forEach(c => characters.add(c));
+       entities.locations.forEach(l => locations.add(l));
+       entities.objects.forEach(o => objects.add(o));
+       entities.concepts.forEach(c => concepts.add(c));
+     });
+     
+     return {
+       characters: [...characters],
+       locations: [...locations],
+       objects: [...objects],
+       concepts: [...concepts],
+       timestamp: Date.now()
+     };
+   }
+ }
+ 
+ module.exports = SceneAnalysisService; 
```

---

### Personalized Recommendations Service
Now, let's create a recommendation service:

---

```diff
- 
+ const axios = require('axios');
+ const { OpenAI } = require('openai');
+ 
+ /**
+  * Service for generating personalized content recommendations
+  */
+ class RecommendationService {
+   constructor(tmdbApiKey, openaiApiKey) {
+     this.tmdbApiKey = tmdbApiKey || process.env.TMDB_API_KEY;
+     this.baseUrl = 'https://api.themoviedb.org/3';
+     this.openai = new OpenAI({
+       apiKey: openaiApiKey || process.env.OPENAI_API_KEY
+     });
+     
+     // In-memory user profile store
+     // In production, this would be stored in a database
+     this.userProfiles = new Map();
+   }
+ 
+   /**
+    * Track user interaction with content
+    * @param {string} userId - User identifier
+    * @param {Object} content - Content information (id, type, title, etc.)
+    * @param {string} action - Interaction type (watch, search, question, like, dislike)
+    * @param {Object} details - Additional details about the interaction
+    */
+   trackUserInteraction(userId, content, action, details = {}) {
+     if (!userId || !content || !action) return;
+ 
+     // Initialize user profile if it doesn't exist
+     if (!this.userProfiles.has(userId)) {
+       this.userProfiles.set(userId, {
+         userId,
+         interactionHistory: [],
+         contentHistory: [],
+         preferences: {
+           genres: {},
+           actors: {},
+           directors: {},
+           keywords: {}
+         },
+         lastUpdated: Date.now()
+       });
+     }
+ 
+     const profile = this.userProfiles.get(userId);
+     
+     // Add to interaction history
+     profile.interactionHistory.push({
+       timestamp: Date.now(),
+       action,
+       contentId: content.id,
+       contentType: content.type,
+       contentTitle: content.title,
+       details
+     });
+     
+     // Keep interaction history at a reasonable size
+     if (profile.interactionHistory.length > 100) {
+       profile.interactionHistory = profile.interactionHistory.slice(-100);
+     }
+     
+     // Update content history for watched items
+     if (action === 'watch' && !profile.contentHistory.some(item => item.id === content.id)) {
+       profile.contentHistory.push({
+         id: content.id,
+         type: content.type,
+         title: content.title,
+         watchDate: Date.now(),
+         genres: content.genres || []
+       });
+       
+       // Keep content history at a reasonable size
+       if (profile.contentHistory.length > 50) {
+         profile.contentHistory = profile.contentHistory.slice(-50);
+       }
+     }
+     
+     // Update preferences based on interactions
+     this.updatePreferences(profile, content, action, details);
+     
+     // Update last updated timestamp
+     profile.lastUpdated = Date.now();
+   }
+   
+   /**
+    * Update user preferences based on content interaction
+    * @param {Object} profile - User profile
+    * @param {Object} content - Content information
+    * @param {string} action - Interaction type
+    * @param {Object} details - Additional details
+    */
+   updatePreferences(profile, content, action, details) {
+     // Weight modifiers based on action
+     const weights = {
+       watch: 2,
+       search: 1,
+       question: 0.5,
+       like: 3,
+       dislike: -2
+     };
+     
+     const weight = weights[action] || 1;
+     
+     // Update genre preferences
+     if (content.genres && Array.isArray(content.genres)) {
+       content.genres.forEach(genre => {
+         profile.preferences.genres[genre] = (profile.preferences.genres[genre] || 0) + weight;
+       });
+     }
+     
+     // Update actor preferences
+     if (content.cast && Array.isArray(content.cast)) {
+       content.cast.forEach((actor, index) => {
+         // Weigh leading actors more heavily
+         const actorWeight = weight * (1 - (index * 0.1));
+         if (actorWeight > 0) {
+           profile.preferences.actors[actor.name] = (profile.preferences.actors[actor.name] || 0) + actorWeight;
+         }
+       });
+     }
+     
+     // Update keyword preferences
+     if (content.keywords && Array.isArray(content.keywords)) {
+       content.keywords.forEach(keyword => {
+         if (typeof keyword === 'object' && keyword.name) {
+           profile.preferences.keywords[keyword.name] = (profile.preferences.keywords[keyword.name] || 0) + weight;
+         } else if (typeof keyword === 'string') {
+           profile.preferences.keywords[keyword] = (profile.preferences.keywords[keyword] || 0) + weight;
+         }
+       });
+     }
+   }
+   
+   /**
+    * Get personalized recommendations
+    * @param {string} userId - User identifier
+    * @param {number} limit - Maximum number of recommendations
+    * @returns {Promise<Array>} Recommended content
+    */
+   async getRecommendations(userId, limit = 10) {
+     try {
+       if (!this.userProfiles.has(userId)) {
+         return this.getPopularContent(limit);
+       }
+       
+       const profile = this.userProfiles.get(userId);
+       
+       // If profile has limited history, supplement with popular content
+       if (profile.contentHistory.length < 3) {
+         return this.getPopularContent(limit);
+       }
+       
+       // Get top genres
+       const topGenres = this.getTopEntities(profile.preferences.genres, 3);
+       
+       // Get top actors
+       const topActors = this.getTopEntities(profile.preferences.actors, 3);
+       
+       // Get top keywords
+       const topKeywords = this.getTopEntities(profile.preferences.keywords, 5);
+       
+       // Get recommendations based on recently watched items
+       const recentItems = profile.contentHistory.slice(-3);
+       const similarContentPromises = recentItems.map(item => 
+         this.getSimilarContent(item.id, item.type));
+       
+       const similarContent = await Promise.all(similarContentPromises);
+       let recommendations = [].concat(...similarContent);
+       
+       // Get recommendations based on user preferences
+       const discoveryRecommendations = await this.getDiscoveryRecommendations(
+         topGenres.map(g => g.name), 
+         topKeywords.map(k => k.name)
+       );
+       
+       recommendations = [...recommendations, ...discoveryRecommendations];
+       
+       // Filter out already watched content
+       recommendations = recommendations.filter(item => 
+         !profile.contentHistory.some(watched => watched.id === item.id));
+       
+       // Remove duplicates
+       recommendations = this.removeDuplicates(recommendations, 'id');
+       
+       // Score recommendations based on user preferences
+       recommendations = this.scoreRecommendations(recommendations, profile);
+       
+       // Sort by score and limit
+       return recommendations
+         .sort((a, b) => b.score - a.score)
+         .slice(0, limit);
+     } catch (error) {
+       console.error('Error getting recommendations:', error);
+       return this.getPopularContent(limit);
+     }
+   }
+   
+   /**
+    * Get similar content based on a reference item
+    * @param {string} itemId - Content ID
+    * @param {string} type - Content type (movie or tv)
+    * @returns {Promise<Array>} Similar content items
+    */
+   async getSimilarContent(itemId, type) {
+     try {
+       const response = await axios.get(`${this.baseUrl}/${type}/${itemId}/similar`, {
+         params: {
+           api_key: this.tmdbApiKey
+         }
+       });
+       
+       return response.data.results.map(item => ({
+         id: item.id,
+         type: type,
+         title: type === 'movie' ? item.title : item.name,
+         overview: item.overview,
+         poster: item.poster_path ? `https://image.tmdb.org/t/p/w500${item.poster_path}` : null,
+         backdrop: item.backdrop_path ? `https://image.tmdb.org/t/p/original${item.backdrop_path}` : null,
+         year: type === 'movie' ? 
+           (item.release_date ? item.release_date.split('-')[0] : null) : 
+           (item.first_air_date ? item.first_air_date.split('-')[0] : null),
+         source: 'similar'
+       }));
+     } catch (error) {
+       console.error('Error getting similar content:', error);
+       return [];
+     }
+   }
+   
+   /**
+    * Get discovery recommendations based on genres and keywords
+    * @param {Array<string>} genres - Preferred genres
+    * @param {Array<string>} keywords - Preferred keywords
+    * @returns {Promise<Array>} Discovery recommendations
+    */
+   async getDiscoveryRecommendations(genres, keywords) {
+     try {
+       // Get genre IDs from TMDB
+       const genreMap = await this.getGenreMap();
+       const genreIds = genres
+         .map(name => {
+           const genre = Object.values(genreMap).find(g => g.name.toLowerCase() === name.toLowerCase());
+           return genre ? genre.id : null;
+         })
+         .filter(Boolean);
+       
+       // Get recommendations for both movies and TV shows
+       const moviePromise = axios.get(`${this.baseUrl}/discover/movie`, {
+         params: {
+           api_key: this.tmdbApiKey,
+           sort_by: 'popularity.desc',
+           with_genres: genreIds.join(','),
+           with_keywords: keywords.join('|')
+         }
+       });
+       
+       const tvPromise = axios.get(`${this.baseUrl}/discover/tv`, {
+         params: {
+           api_key: this.tmdbApiKey,
+           sort_by: 'popularity.desc',
+           with_genres: genreIds.join(','),
+           with_keywords: keywords.join('|')
+         }
+       });
+       
+       const [movieResponse, tvResponse] = await Promise.all([moviePromise, tvPromise]);
+       
+       const movieRecommendations = movieResponse.data.results.map(item => ({
+         id: item.id,
+         type: 'movie',
+         title: item.title,
+         overview: item.overview,
+         poster: item.poster_path ? `https://image.tmdb.org/t/p/w500${item.poster_path}` : null,
+         backdrop: item.backdrop_path ? `https://image.tmdb.org/t/p/original${item.backdrop_path}` : null,
+         year: item.release_date ? item.release_date.split('-')[0] : null,
+         source: 'discovery'
+       }));
+       
+       const tvRecommendations = tvResponse.data.results.map(item => ({
+         id: item.id,
+         type: 'tv',
+         title: item.name,
+         overview: item.overview,
+         poster: item.poster_path ? `https://image.tmdb.org/t/p/w500${item.poster_path}` : null,
+         backdrop: item.backdrop_path ? `https://image.tmdb.org/t/p/original${item.backdrop_path}` : null,
+         year: item.first_air_date ? item.first_air_date.split('-')[0] : null,
+         source: 'discovery'
+       }));
+       
+       return [...movieRecommendations, ...tvRecommendations];
+     } catch (error) {
+       console.error('Error getting discovery recommendations:', error);
+       return [];
+     }
+   }
+   
+   /**
+    * Get popular content as fallback
+    * @param {number} limit - Maximum number of items
+    * @returns {Promise<Array>} Popular content
+    */
+   async getPopularContent(limit = 10) {
+     try {
+       // Get popular movies and TV shows
+       const moviePromise = axios.get(`${this.baseUrl}/movie/popular`, {
+         params: {
+           api_key: this.tmdbApiKey
+         }
+       });
+       
+       const tvPromise = axios.get(`${this.baseUrl}/tv/popular`, {
+         params: {
+           api_key: this.tmdbApiKey
+         }
+       });
+       
+       const [movieResponse, tvResponse] = await Promise.all([moviePromise, tvPromise]);
+       
+       const movies = movieResponse.data.results.map(item => ({
+         id: item.id,
+         type: 'movie',
+         title: item.title,
+         overview: item.overview,
+         poster: item.poster_path ? `https://image.tmdb.org/t/p/w500${item.poster_path}` : null,
+         backdrop: item.backdrop_path ? `https://image.tmdb.org/t/p/original${item.backdrop_path}` : null,
+         year: item.release_date ? item.release_date.split('-')[0] : null,
+         source: 'popular'
+       }));
+       
+       const tvShows = tvResponse.data.results.map(item => ({
+         id: item.id,
+         type: 'tv',
+         title: item.name,
+         overview: item.overview,
+         poster: item.poster_path ? `https://image.tmdb.org/t/p/w500${item.poster_path}` : null,
+         backdrop: item.backdrop_path ? `https://image.tmdb.org/t/p/original${item.backdrop_path}` : null,
+         year: item.first_air_date ? item.first_air_date.split('-')[0] : null,
+         source: 'popular'
+       }));
+       
+       // Combine and shuffle to provide a mix of content types
+       const combined = [...movies, ...tvShows];
+       this.shuffleArray(combined);
+       
+       return combined.slice(0, limit);
+     } catch (error) {
+       console.error('Error getting popular content:', error);
+       return [];
+     }
+   }
+   
+   /**
+    * Get TMDB genre mapping
+    * @returns {Promise<Object>} Genre ID to name mapping
+    */
+   async getGenreMap() {
+     try {
+       const movieGenresPromise = axios.get(`${this.baseUrl}/genre/movie/list`, {
+         params: {
+           api_key: this.tmdbApiKey
+         }
+       });
+       
+       const tvGenresPromise = axios.get(`${this.baseUrl}/genre/tv/list`, {
+         params: {
+           api_key: this.tmdbApiKey
+         }
+       });
+       
+       const [movieGenres, tvGenres] = await Promise.all([movieGenresPromise, tvGenresPromise]);
+       
+       const genreMap = {};
+       
+       movieGenres.data.genres.forEach(genre => {
+         genreMap[`movie_${genre.id}`] = { id: genre.id, name: genre.name, type: 'movie' };
+       });
+       
+       tvGenres.data.genres.forEach(genre => {
+         genreMap[`tv_${genre.id}`] = { id: genre.id, name: genre.name, type: 'tv' };
+       });
+       
+       return genreMap;
+     } catch (error) {
+       console.error('Error getting genre map:', error);
+       return {};
+     }
+   }
+   
+   /**
+    * Score recommendations based on user preferences
+    * @param {Array} recommendations - Recommended content
+    * @param {Object} profile - User profile
+    * @returns {Array} Scored recommendations
+    */
+   async scoreRecommendations(recommendations, profile) {
+     // Get content details for each recommendation to access genres and keywords
+     const detailedRecommendations = await this.getContentDetails(recommendations);
+     
+     return detailedRecommendations.map(item => {
+       let score = 1; // Base score
+       
+       // Score based on genres
+       if (item.genres && Array.isArray(item.genres)) {
+         item.genres.forEach(genre => {
+           const genrePreference = profile.preferences.genres[genre] || 0;
+           score += genrePreference * 0.5;
+         });
+       }
+       
+       // Score based on actors
+       if (item.cast && Array.isArray(item.cast)) {
+         item.cast.forEach(actor => {
+           const actorPreference = profile.preferences.actors[actor.name] || 0;
+           score += actorPreference * 0.3;
+         });
+       }
+       
+       // Score based on keywords
+       if (item.keywords && Array.isArray(item.keywords)) {
+         item.keywords.forEach(keyword => {
+           const keywordName = typeof keyword === 'object' ? keyword.name : keyword;
+           const keywordPreference = profile.preferences.keywords[keywordName] || 0;
+           score += keywordPreference * 0.2;
+         });
+       }
+       
+       // Give extra points to items from similar content
+       if (item.source === 'similar') {
+         score += 1;
+       }
+       
+       return { ...item, score };
+     });
+   }
+   
+   /**
+    * Get detailed content information for recommendations
+    * @param {Array} items - Content items
+    * @returns {Promise<Array>} Detailed content items
+    */
+   async getContentDetails(items) {
+     try {
+       // Group items by type to batch requests
+       const movieIds = items.filter(item => item.type === 'movie').map(item => item.id);
+       const tvIds = items.filter(item => item.type === 'tv').map(item => item.id);
+       
+       const detailedItems = [...items];
+       
+       // Get detailed information for movies
+       await Promise.all(movieIds.map(async (id) => {
+         try {
+           const response = await axios.get(`${this.baseUrl}/movie/${id}`, {
+             params: {
+               api_key: this.tmdbApiKey,
+               append_to_response: 'credits,keywords'
+             }
+           });
+           
+           const index = detailedItems.findIndex(item => item.id === id && item.type === 'movie');
+           if (index !== -1) {
+             detailedItems[index] = {
+               ...detailedItems[index],
+               genres: response.data.genres.map(g => g.name),
+               cast: response.data.credits.cast.slice(0, 5).map(actor => ({
+                 name: actor.name,
+                 character: actor.character
+               })),
+               keywords: response.data.keywords.keywords || []
+             };
+           }
+         } catch (error) {
+           console.error(`Error getting movie details for ID ${id}:`, error);
+         }
+       }));
+       
+       // Get detailed information for TV shows
+       await Promise.all(tvIds.map(async (id) => {
+         try {
+           const response = await axios.get(`${this.baseUrl}/tv/${id}`, {
+             params: {
+               api_key: this.tmdbApiKey,
+               append_to_response: 'credits,keywords'
+             }
+           });
+           
+           const index = detailedItems.findIndex(item => item.id === id && item.type === 'tv');
+           if (index !== -1) {
+             detailedItems[index] = {
+               ...detailedItems[index],
+               genres: response.data.genres.map(g => g.name),
+               cast: response.data.credits.cast.slice(0, 5).map(actor => ({
+                 name: actor.name,
+                 character: actor.character
+               })),
+               keywords: response.data.keywords.results || []
+             };
+           }
+         } catch (error) {
+           console.error(`Error getting TV details for ID ${id}:`, error);
+         }
+       }));
+       
+       return detailedItems;
+     } catch (error) {
+       console.error('Error getting content details:', error);
+       return items;
+     }
+   }
+   
+   /**
+    * Get top entities from a preference map
+    * @param {Object} preferences - Map of entity names to preference scores
+    * @param {number} limit - Maximum number of entities to return
+    * @returns {Array} Top entities with scores
+    */
+   getTopEntities(preferences, limit = 3) {
+     return Object.entries(preferences)
+       .map(([name, score]) => ({ name, score }))
+       .filter(item => item.score > 0)
+       .sort((a, b) => b.score - a.score)
+       .slice(0, limit);
+   }
+   
+   /**
+    * Remove duplicate items from an array based on a key
+    * @param {Array} array - Array of items
+    * @param {string} key - Key to use for deduplication
+    * @returns {Array} Deduplicated array
+    */
+   removeDuplicates(array, key) {
+     return Array.from(new Map(array.map(item => [item[key], item])).values());
+   }
+   
+   /**
+    * Shuffle an array in place
+    * @param {Array} array - Array to shuffle
+    */
+   shuffleArray(array) {
+     for (let i = array.length - 1; i > 0; i--) {
+       const j = Math.floor(Math.random() * (i + 1));
+       [array[i], array[j]] = [array[j], array[i]];
+     }
+   }
+   
+   /**
+    * Generate AI-enhanced personalized recommendations
+    * @param {string} userId - User identifier
+    * @param {Object} profile - User profile data
+    * @param {number} limit - Maximum number of recommendations
+    * @returns {Promise<Array>} Enhanced recommendations
+    */
+   async generateAIRecommendations(userId, limit = 5) {
+     try {
+       if (!this.userProfiles.has(userId)) {
+         return [];
+       }
+       
+       const profile = this.userProfiles.get(userId);
+       
+       // Extract user preferences and history
+       const topGenres = this.getTopEntities(profile.preferences.genres, 5)
+         .map(g => g.name)
+         .join(', ');
+       
+       const recentlyWatched = profile.contentHistory
+         .slice(-5)
+         .map(c => c.title)
+         .join(', ');
+       
+       const topKeywords = this.getTopEntities(profile.preferences.keywords, 5)
+         .map(k => k.name)
+         .join(', ');
+       
+       const topActors = this.getTopEntities(profile.preferences.actors, 5)
+         .map(a => a.name)
+         .join(', ');
+       
+       // Extract recent questions to understand interests
+       const recentQuestions = profile.interactionHistory
+         .filter(i => i.action === 'question')
+         .slice(-10)
+         .map(i => i.details.question || '')
+         .join('; ');
+       
+       // Generate recommendations using GPT
+       const response = await this.openai.chat.completions.create({
+         model: "gpt-4",
+         messages: [
+           {
+             role: "system",
+             content: `You are a personalized content recommendation system. Based on the user's viewing history, 
+             preferences, and questions they've asked, recommend content they might enjoy. 
+             For each recommendation, provide a brief reason why they might like it that references their specific tastes.
+             Format your response as a JSON array with objects containing: title, type (movie/tv), year, and reason.`
+           },
+           {
+             role: "user",
+             content: `Generate ${limit} highly personalized recommendations based on this profile:
+             
+             - Favorite genres: ${topGenres || 'No data'}
+             - Recently watched: ${recentlyWatched || 'No data'}
+             - Favorite actors: ${topActors || 'No data'}
+             - Interests based on keywords: ${topKeywords || 'No data'}
+             - Recent questions asked: ${recentQuestions || 'No data'}`
+           }
+         ],
+         response_format: { type: "json_object" },
+         max_tokens: 1000
+       });
+       
+       // Parse the response
+       let recommendations;
+       try {
+         const content = JSON.parse(response.choices[0].message.content);
+         recommendations = content.recommendations || [];
+       } catch (error) {
+         console.error('Error parsing AI recommendations:', error);
+         return [];
+       }
+       
+       return recommendations.map(rec => ({
+         title: rec.title,
+         type: rec.type,
+         year: rec.year,
+         reason: rec.reason,
+         source: 'ai'
+       }));
+     } catch (error) {
+       console.error('Error generating AI recommendations:', error);
+       return [];
+     }
+   }
+ }
+ 
+ module.exports = RecommendationService; 
```

---

## 2. Multi-device Experience
Now, I'll create the services needed for shared viewing experience and collaborative Q&A:

---

```diff
- 
+ /**
+  * Service for managing shared viewing sessions with synchronized playback
+  * and collaborative Q&A across multiple devices
+  */
+ class SharedViewingService {
+   constructor() {
+     // Map of session IDs to session data
+     this.sessions = new Map();
+     
+     // Map of user IDs to session IDs
+     this.userSessions = new Map();
+     
+     // Map of session IDs to arrays of connected socket IDs
+     this.sessionSockets = new Map();
+   }
+   
+   /**
+    * Create a new shared viewing session
+    * @param {string} hostUserId - ID of the user hosting the session
+    * @param {Object} mediaInfo - Information about the media being watched
+    * @returns {Object} Session information
+    */
+   createSession(hostUserId, mediaInfo) {
+     const sessionId = this.generateSessionId();
+     const timestamp = Date.now();
+     
+     const session = {
+       id: sessionId,
+       hostUserId,
+       mediaInfo,
+       participants: [{ userId: hostUserId, role: 'host', joinedAt: timestamp }],
+       state: {
+         isPlaying: false,
+         currentTime: 0,
+         lastUpdated: timestamp
+       },
+       chat: [],
+       questions: [],
+       createdAt: timestamp,
+       lastActive: timestamp
+     };
+     
+     this.sessions.set(sessionId, session);
+     this.userSessions.set(hostUserId, sessionId);
+     this.sessionSockets.set(sessionId, []);
+     
+     return {
+       sessionId,
+       joinCode: this.generateJoinCode(sessionId)
+     };
+   }
+   
+   /**
+    * Join an existing shared viewing session
+    * @param {string} userId - ID of the user joining
+    * @param {string} sessionId - ID of the session to join
+    * @param {string} joinCode - Code required to join the session
+    * @returns {Object} Session information or error
+    */
+   joinSession(userId, sessionId, joinCode) {
+     // Validate the join code
+     if (!this.validateJoinCode(sessionId, joinCode)) {
+       return { error: 'Invalid join code' };
+     }
+     
+     // Check if the session exists
+     if (!this.sessions.has(sessionId)) {
+       return { error: 'Session not found' };
+     }
+     
+     const session = this.sessions.get(sessionId);
+     const timestamp = Date.now();
+     
+     // Check if user is already in the session
+     const existingParticipant = session.participants.find(p => p.userId === userId);
+     
+     if (!existingParticipant) {
+       // Add the user to the session
+       session.participants.push({
+         userId,
+         role: 'viewer',
+         joinedAt: timestamp
+       });
+     } else {
+       // Update the existing participant's last activity
+       existingParticipant.lastActive = timestamp;
+     }
+     
+     // Update user-session mapping
+     this.userSessions.set(userId, sessionId);
+     
+     // Update session last active timestamp
+     session.lastActive = timestamp;
+     
+     return {
+       session: this.getSessionInfo(sessionId)
+     };
+   }
+   
+   /**
+    * Leave a shared viewing session
+    * @param {string} userId - ID of the user leaving
+    * @returns {boolean} Success status
+    */
+   leaveSession(userId) {
+     // Check if the user is in a session
+     if (!this.userSessions.has(userId)) {
+       return false;
+     }
+     
+     const sessionId = this.userSessions.get(userId);
+     const session = this.sessions.get(sessionId);
+     
+     if (!session) {
+       this.userSessions.delete(userId);
+       return false;
+     }
+     
+     // Remove the user from the session participants
+     session.participants = session.participants.filter(p => p.userId !== userId);
+     
+     // Update the user-session mapping
+     this.userSessions.delete(userId);
+     
+     // If the host leaves, either promote another participant or close the session
+     if (session.hostUserId === userId) {
+       if (session.participants.length > 0) {
+         // Promote the longest-connected participant to host
+         const newHost = session.participants.sort((a, b) => a.joinedAt - b.joinedAt)[0];
+         session.hostUserId = newHost.userId;
+         newHost.role = 'host';
+       } else {
+         // No participants left, close the session
+         this.closeSession(sessionId);
+         return true;
+       }
+     }
+     
+     // Update session last active timestamp
+     session.lastActive = Date.now();
+     
+     return true;
+   }
+   
+   /**
+    * Close a shared viewing session
+    * @param {string} sessionId - ID of the session to close
+    * @returns {boolean} Success status
+    */
+   closeSession(sessionId) {
+     if (!this.sessions.has(sessionId)) {
+       return false;
+     }
+     
+     const session = this.sessions.get(sessionId);
+     
+     // Remove all user-session mappings for this session
+     session.participants.forEach(participant => {
+       this.userSessions.delete(participant.userId);
+     });
+     
+     // Delete the session and its socket mappings
+     this.sessions.delete(sessionId);
+     this.sessionSockets.delete(sessionId);
+     
+     return true;
+   }
+   
+   /**
+    * Update the playback state for a session
+    * @param {string} sessionId - Session ID
+    * @param {string} userId - User making the update
+    * @param {Object} state - New playback state
+    * @returns {Object} Updated session state or error
+    */
+   updatePlaybackState(sessionId, userId, state) {
+     if (!this.sessions.has(sessionId)) {
+       return { error: 'Session not found' };
+     }
+     
+     const session = this.sessions.get(sessionId);
+     
+     // Only the host or participants with control permissions can update playback
+     const participant = session.participants.find(p => p.userId === userId);
+     if (!participant || (participant.role !== 'host' && !participant.canControl)) {
+       return { error: 'Permission denied' };
+     }
+     
+     // Update the playback state
+     session.state = {
+       isPlaying: state.isPlaying !== undefined ? state.isPlaying : session.state.isPlaying,
+       currentTime: state.currentTime !== undefined ? state.currentTime : session.state.currentTime,
+       lastUpdated: Date.now()
+     };
+     
+     // Update session last active timestamp
+     session.lastActive = Date.now();
+     
+     return { state: session.state };
+   }
+   
+   /**
+    * Add a socket connection to a session
+    * @param {string} sessionId - Session ID
+    * @param {string} socketId - Socket ID
+    * @returns {boolean} Success status
+    */
+   addSocketToSession(sessionId, socketId) {
+     if (!this.sessions.has(sessionId) || !this.sessionSockets.has(sessionId)) {
+       return false;
+     }
+     
+     const sockets = this.sessionSockets.get(sessionId);
+     if (!sockets.includes(socketId)) {
+       sockets.push(socketId);
+     }
+     
+     return true;
+   }
+   
+   /**
+    * Remove a socket connection from a session
+    * @param {string} socketId - Socket ID to remove
+    * @returns {boolean} Success status
+    */
+   removeSocketFromAllSessions(socketId) {
+     for (const [sessionId, sockets] of this.sessionSockets.entries()) {
+       const index = sockets.indexOf(socketId);
+       if (index !== -1) {
+         sockets.splice(index, 1);
+       }
+     }
+     
+     return true;
+   }
+   
+   /**
+    * Get the active session for a user
+    * @param {string} userId - User ID
+    * @returns {Object} Session information or null
+    */
+   getUserSession(userId) {
+     if (!this.userSessions.has(userId)) {
+       return null;
+     }
+     
+     const sessionId = this.userSessions.get(userId);
+     return this.getSessionInfo(sessionId);
+   }
+   
+   /**
+    * Get session information
+    * @param {string} sessionId - Session ID
+    * @returns {Object} Session information or null
+    */
+   getSessionInfo(sessionId) {
+     if (!this.sessions.has(sessionId)) {
+       return null;
+     }
+     
+     const session = this.sessions.get(sessionId);
+     
+     // Return a clean version of the session object
+     return {
+       id: session.id,
+       hostUserId: session.hostUserId,
+       mediaInfo: session.mediaInfo,
+       participants: session.participants.map(p => ({
+         userId: p.userId,
+         role: p.role,
+         joinedAt: p.joinedAt
+       })),
+       state: { ...session.state },
+       chatCount: session.chat.length,
+       questionCount: session.questions.length,
+       createdAt: session.createdAt,
+       lastActive: session.lastActive
+     };
+   }
+   
+   /**
+    * Add a chat message to a session
+    * @param {string} sessionId - Session ID
+    * @param {string} userId - User ID sending the message
+    * @param {string} message - Chat message
+    * @returns {Object} Added message or error
+    */
+   addChatMessage(sessionId, userId, message) {
+     if (!this.sessions.has(sessionId)) {
+       return { error: 'Session not found' };
+     }
+     
+     const session = this.sessions.get(sessionId);
+     
+     // Check if the user is a participant in the session
+     if (!session.participants.some(p => p.userId === userId)) {
+       return { error: 'Not a participant in this session' };
+     }
+     
+     const timestamp = Date.now();
+     const chatMessage = {
+       id: this.generateId(),
+       userId,
+       message,
+       timestamp,
+       type: 'chat'
+     };
+     
+     session.chat.push(chatMessage);
+     
+     // Limit chat history size
+     if (session.chat.length > 100) {
+       session.chat = session.chat.slice(-100);
+     }
+     
+     // Update session last active timestamp
+     session.lastActive = timestamp;
+     
+     return { message: chatMessage };
+   }
+   
+   /**
+    * Add a question to a session
+    * @param {string} sessionId - Session ID
+    * @param {string} userId - User ID asking the question
+    * @param {string} question - Question text
+    * @param {number} videoTime - Current video time when the question was asked
+    * @returns {Object} Added question or error
+    */
+   addQuestion(sessionId, userId, question, videoTime) {
+     if (!this.sessions.has(sessionId)) {
+       return { error: 'Session not found' };
+     }
+     
+     const session = this.sessions.get(sessionId);
+     
+     // Check if the user is a participant in the session
+     if (!session.participants.some(p => p.userId === userId)) {
+       return { error: 'Not a participant in this session' };
+     }
+     
+     const timestamp = Date.now();
+     const questionObj = {
+       id: this.generateId(),
+       userId,
+       question,
+       videoTime,
+       timestamp,
+       type: 'question',
+       answers: [],
+       likes: []
+     };
+     
+     session.questions.push(questionObj);
+     
+     // Update session last active timestamp
+     session.lastActive = timestamp;
+     
+     return { question: questionObj };
+   }
+   
+   /**
+    * Add an answer to a question
+    * @param {string} sessionId - Session ID
+    * @param {string} questionId - Question ID
+    * @param {string} userId - User ID answering
+    * @param {string} answer - Answer text
+    * @returns {Object} Updated question or error
+    */
+   addAnswer(sessionId, questionId, userId, answer) {
+     if (!this.sessions.has(sessionId)) {
+       return { error: 'Session not found' };
+     }
+     
+     const session = this.sessions.get(sessionId);
+     
+     // Check if the user is a participant in the session
+     if (!session.participants.some(p => p.userId === userId)) {
+       return { error: 'Not a participant in this session' };
+     }
+     
+     // Find the question
+     const questionIndex = session.questions.findIndex(q => q.id === questionId);
+     if (questionIndex === -1) {
+       return { error: 'Question not found' };
+     }
+     
+     const question = session.questions[questionIndex];
+     
+     const timestamp = Date.now();
+     const answerObj = {
+       id: this.generateId(),
+       userId,
+       answer,
+       timestamp,
+       likes: []
+     };
+     
+     question.answers.push(answerObj);
+     
+     // Update session last active timestamp
+     session.lastActive = timestamp;
+     
+     return { question: session.questions[questionIndex] };
+   }
+   
+   /**
+    * Like a question or answer
+    * @param {string} sessionId - Session ID
+    * @param {string} itemId - Question or answer ID
+    * @param {string} userId - User ID liking the item
+    * @param {string} type - Type of item (question or answer)
+    * @returns {Object} Updated question or error
+    */
+   likeItem(sessionId, itemId, userId, type) {
+     if (!this.sessions.has(sessionId)) {
+       return { error: 'Session not found' };
+     }
+     
+     const session = this.sessions.get(sessionId);
+     
+     // Check if the user is a participant in the session
+     if (!session.participants.some(p => p.userId === userId)) {
+       return { error: 'Not a participant in this session' };
+     }
+     
+     if (type === 'question') {
+       // Find the question
+       const questionIndex = session.questions.findIndex(q => q.id === itemId);
+       if (questionIndex === -1) {
+         return { error: 'Question not found' };
+       }
+       
+       const question = session.questions[questionIndex];
+       
+       // Add like if not already liked
+       if (!question.likes.includes(userId)) {
+         question.likes.push(userId);
+       }
+       
+       return { question };
+     } else if (type === 'answer') {
+       // Find the question containing the answer
+       for (const question of session.questions) {
+         const answerIndex = question.answers.findIndex(a => a.id === itemId);
+         if (answerIndex !== -1) {
+           const answer = question.answers[answerIndex];
+           
+           // Add like if not already liked
+           if (!answer.likes.includes(userId)) {
+             answer.likes.push(userId);
+           }
+           
+           return { question };
+         }
+       }
+       
+       return { error: 'Answer not found' };
+     }
+     
+     return { error: 'Invalid item type' };
+   }
+   
+   /**
+    * Get chat history for a session
+    * @param {string} sessionId - Session ID
+    * @param {number} limit - Maximum number of messages to return
+    * @param {number} before - Timestamp to get messages before
+    * @returns {Array} Chat messages
+    */
+   getChatHistory(sessionId, limit = 50, before = Date.now()) {
+     if (!this.sessions.has(sessionId)) {
+       return [];
+     }
+     
+     const session = this.sessions.get(sessionId);
+     
+     return session.chat
+       .filter(msg => msg.timestamp < before)
+       .sort((a, b) => b.timestamp - a.timestamp)
+       .slice(0, limit);
+   }
+   
+   /**
+    * Get questions for a session
+    * @param {string} sessionId - Session ID
+    * @param {string} sortBy - Sort method (newest, popular, unanswered)
+    * @param {number} limit - Maximum number of questions to return
+    * @returns {Array} Questions
+    */
+   getQuestions(sessionId, sortBy = 'newest', limit = 20) {
+     if (!this.sessions.has(sessionId)) {
+       return [];
+     }
+     
+     const session = this.sessions.get(sessionId);
+     
+     let questions = [...session.questions];
+     
+     // Sort questions
+     if (sortBy === 'newest') {
+       questions.sort((a, b) => b.timestamp - a.timestamp);
+     } else if (sortBy === 'popular') {
+       questions.sort((a, b) => b.likes.length - a.likes.length);
+     } else if (sortBy === 'unanswered') {
+       questions = questions.filter(q => q.answers.length === 0);
+       questions.sort((a, b) => b.timestamp - a.timestamp);
+     }
+     
+     return questions.slice(0, limit);
+   }
+   
+   /**
+    * Send information to mobile device
+    * @param {string} sessionId - Session ID
+    * @param {string} userId - User ID sending information
+    * @param {string} type - Type of information (link, note, timestamp)
+    * @param {Object} data - Information data
+    * @returns {Object} Result
+    */
+   sendToMobile(sessionId, userId, type, data) {
+     if (!this.sessions.has(sessionId)) {
+       return { error: 'Session not found' };
+     }
+     
+     const session = this.sessions.get(sessionId);
+     
+     // Check if the user is a participant in the session
+     if (!session.participants.some(p => p.userId === userId)) {
+       return { error: 'Not a participant in this session' };
+     }
+     
+     const timestamp = Date.now();
+     const info = {
+       id: this.generateId(),
+       userId,
+       type,
+       data,
+       timestamp,
+       videoTime: session.state.currentTime
+     };
+     
+     // We'll return the info object to be sent through WebSockets to the mobile device
+     return { info };
+   }
+   
+   /**
+    * Generate a unique session ID
+    * @returns {string} Session ID
+    */
+   generateSessionId() {
+     return `session_${Date.now()}_${Math.floor(Math.random() * 1000000)}`;
+   }
+   
+   /**
+    * Generate a unique ID
+    * @returns {string} Unique ID
+    */
+   generateId() {
+     return `${Date.now()}_${Math.floor(Math.random() * 1000000)}`;
+   }
+   
+   /**
+    * Generate a join code for a session
+    * @param {string} sessionId - Session ID
+    * @returns {string} Join code
+    */
+   generateJoinCode(sessionId) {
+     // Create a 6-character alphanumeric code
+     const characters = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789';
+     let code = '';
+     
+     for (let i = 0; i < 6; i++) {
+       const randomIndex = Math.floor(Math.random() * characters.length);
+       code += characters.charAt(randomIndex);
+     }
+     
+     return code;
+   }
+   
+   /**
+    * Validate a join code for a session
+    * @param {string} sessionId - Session ID
+    * @param {string} joinCode - Join code to validate
+    * @returns {boolean} Validation result
+    */
+   validateJoinCode(sessionId, joinCode) {
+     // In a real implementation, we would store and validate actual join codes
+     // For this prototype, we'll accept any non-empty string as valid
+     return joinCode && joinCode.length === 6;
+   }
+   
+   /**
+    * Clean up expired sessions
+    * @param {number} maxAgeMs - Maximum age of inactive sessions in milliseconds
+    */
+   cleanupExpiredSessions(maxAgeMs = 3600000) { // Default: 1 hour
+     const now = Date.now();
+     
+     for (const [sessionId, session] of this.sessions.entries()) {
+       if (now - session.lastActive > maxAgeMs) {
+         this.closeSession(sessionId);
+       }
+     }
+   }
+   
+   /**
+    * Get session socket IDs
+    * @param {string} sessionId - Session ID
+    * @returns {Array} Socket IDs
+    */
+   getSessionSockets(sessionId) {
+     if (!this.sessionSockets.has(sessionId)) {
+       return [];
+     }
+     
+     return [...this.sessionSockets.get(sessionId)];
+   }
+   
+   /**
+    * Get all active sessions
+    * @returns {Array} Active sessions
+    */
+   getAllSessions() {
+     return Array.from(this.sessions.values()).map(session => ({
+       id: session.id,
+       hostUserId: session.hostUserId,
+       mediaInfo: {
+         title: session.mediaInfo.title
+       },
+       participantCount: session.participants.length,
+       createdAt: session.createdAt,
+       lastActive: session.lastActive
+     }));
+   }
+ }
+ 
+ module.exports = SharedViewingService; 
```

---

### Mobile Send Feature
Let's implement the "Send to Mobile" feature:

---

```diff
- 
+ /**
+  * MobileSaver.js
+  * Component for receiving and saving content sent from the TV app
+  */
+ 
+ class MobileSaver {
+   constructor(connectionManager) {
+     this.connectionManager = connectionManager;
+     this.container = null;
+     this.savedItems = [];
+     this.notificationTimeout = null;
+     
+     // Load saved items from local storage
+     this.loadSavedItems();
+     
+     // Set up event listeners for WebSocket messages
+     this.setupEventListeners();
+   }
+ 
+   /**
+    * Initialize the component in the DOM
+    * @param {HTMLElement} container - Container element
+    */
+   init(container) {
+     this.container = container;
+     this.render();
+   }
+ 
+   /**
+    * Set up WebSocket event listeners
+    */
+   setupEventListeners() {
+     // Listen for mobile save events from the server
+     this.connectionManager.socket.on('mobile:save', (data) => {
+       this.handleNewItem(data);
+     });
+   }
+ 
+   /**
+    * Load saved items from local storage
+    */
+   loadSavedItems() {
+     try {
+       const savedData = localStorage.getItem('memorystream_saved_items');
+       if (savedData) {
+         this.savedItems = JSON.parse(savedData);
+       }
+     } catch (error) {
+       console.error('Error loading saved items:', error);
+       this.savedItems = [];
+     }
+   }
+ 
+   /**
+    * Save items to local storage
+    */
+   saveToPersistentStorage() {
+     try {
+       localStorage.setItem('memorystream_saved_items', JSON.stringify(this.savedItems));
+     } catch (error) {
+       console.error('Error saving items to storage:', error);
+     }
+   }
+ 
+   /**
+    * Handle a new saved item
+    * @param {Object} item - Item to save
+    */
+   handleNewItem(item) {
+     // Add timestamp if not present
+     if (!item.timestamp) {
+       item.timestamp = Date.now();
+     }
+     
+     // Add the item to the saved list
+     this.savedItems.unshift(item);
+     
+     // Limit the number of saved items
+     if (this.savedItems.length > 100) {
+       this.savedItems = this.savedItems.slice(0, 100);
+     }
+     
+     // Save to persistent storage
+     this.saveToPersistentStorage();
+     
+     // Re-render the UI
+     this.render();
+     
+     // Show notification
+     this.showNotification(item);
+   }
+ 
+   /**
+    * Delete a saved item
+    * @param {string} itemId - ID of the item to delete
+    */
+   deleteItem(itemId) {
+     this.savedItems = this.savedItems.filter(item => item.id !== itemId);
+     this.saveToPersistentStorage();
+     this.render();
+   }
+ 
+   /**
+    * Clear all saved items
+    */
+   clearAllItems() {
+     if (confirm('Are you sure you want to delete all saved items?')) {
+       this.savedItems = [];
+       this.saveToPersistentStorage();
+       this.render();
+     }
+   }
+ 
+   /**
+    * Show a notification for a new saved item
+    * @param {Object} item - Saved item
+    */
+   showNotification(item) {
+     // Clear any existing notification
+     if (this.notificationTimeout) {
+       clearTimeout(this.notificationTimeout);
+     }
+     
+     // Create notification element
+     const notification = document.createElement('div');
+     notification.className = 'mobile-saver-notification';
+     
+     let notificationContent = '';
+     switch (item.type) {
+       case 'link':
+         notificationContent = `<h3>Link Saved</h3><p>${item.data.title || 'External content'}</p>`;
+         break;
+       case 'timestamp':
+         notificationContent = `<h3>Timestamp Saved</h3><p>${this.formatTime(item.videoTime)}</p>`;
+         break;
+       case 'note':
+         notificationContent = `<h3>Note Saved</h3><p>${item.data.text.substring(0, 50)}${item.data.text.length > 50 ? '...' : ''}</p>`;
+         break;
+       case 'image':
+         notificationContent = `<h3>Image Saved</h3><p>${item.data.caption || 'Screenshot'}</p>`;
+         break;
+       default:
+         notificationContent = `<h3>Item Saved</h3>`;
+     }
+     
+     notification.innerHTML = notificationContent;
+     
+     // Add to the DOM
+     document.body.appendChild(notification);
+     
+     // Animate in
+     setTimeout(() => {
+       notification.classList.add('visible');
+     }, 10);
+     
+     // Remove after delay
+     this.notificationTimeout = setTimeout(() => {
+       notification.classList.remove('visible');
+       setTimeout(() => {
+         if (notification.parentNode) {
+           notification.parentNode.removeChild(notification);
+         }
+       }, 300); // Matches CSS transition time
+     }, 3000);
+   }
+ 
+   /**
+    * Format seconds as timestamp
+    * @param {number} seconds - Seconds to format
+    * @returns {string} Formatted timestamp
+    */
+   formatTime(seconds) {
+     if (typeof seconds !== 'number') return '00:00';
+     
+     const hours = Math.floor(seconds / 3600);
+     const minutes = Math.floor((seconds % 3600) / 60);
+     const secs = Math.floor(seconds % 60);
+     
+     if (hours > 0) {
+       return `${hours.toString().padStart(2, '0')}:${minutes.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
+     } else {
+       return `${minutes.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
+     }
+   }
+ 
+   /**
+    * Format date for display
+    * @param {number} timestamp - Unix timestamp
+    * @returns {string} Formatted date
+    */
+   formatDate(timestamp) {
+     const date = new Date(timestamp);
+     return date.toLocaleDateString() + ' ' + date.toLocaleTimeString();
+   }
+ 
+   /**
+    * Render the component
+    */
+   render() {
+     if (!this.container) return;
+     
+     // Clear the container
+     this.container.innerHTML = '';
+     
+     // Create the header
+     const header = document.createElement('div');
+     header.className = 'mobile-saver-header';
+     header.innerHTML = `
+       <h2>Saved Items</h2>
+       <button class="clear-all-button" ${this.savedItems.length === 0 ? 'disabled' : ''}>Clear All</button>
+     `;
+     this.container.appendChild(header);
+     
+     // Add event listener to the clear all button
+     const clearButton = header.querySelector('.clear-all-button');
+     clearButton.addEventListener('click', () => this.clearAllItems());
+     
+     // Create the items container
+     const itemsContainer = document.createElement('div');
+     itemsContainer.className = 'mobile-saver-items';
+     
+     if (this.savedItems.length === 0) {
+       // Show empty state
+       itemsContainer.innerHTML = `
+         <div class="empty-state">
+           <p>No saved items yet</p>
+           <p class="hint">Items you save from the TV will appear here</p>
+         </div>
+       `;
+     } else {
+       // Render each saved item
+       this.savedItems.forEach(item => {
+         const itemElement = document.createElement('div');
+         itemElement.className = `saved-item ${item.type}`;
+         itemElement.dataset.id = item.id;
+         
+         let itemContent = '';
+         
+         // Common header for all items
+         const header = `
+           <div class="item-header">
+             <span class="timestamp">${this.formatDate(item.timestamp)}</span>
+             <button class="delete-button" aria-label="Delete">Ã—</button>
+           </div>
+         `;
+         
+         // Content based on item type
+         switch (item.type) {
+           case 'link':
+             itemContent = `
+               ${header}
+               <div class="item-content">
+                 <h3>${item.data.title || 'External Link'}</h3>
+                 <p>${item.data.description || ''}</p>
+                 <a href="${item.data.url}" target="_blank" rel="noopener noreferrer">Open Link</a>
+               </div>
+             `;
+             break;
+             
+           case 'timestamp':
+             itemContent = `
+               ${header}
+               <div class="item-content">
+                 <h3>Saved Moment</h3>
+                 <p class="video-time">${this.formatTime(item.videoTime)}</p>
+                 <p>${item.data.note || ''}</p>
+               </div>
+             `;
+             break;
+             
+           case 'note':
+             itemContent = `
+               ${header}
+               <div class="item-content">
+                 <h3>Note</h3>
+                 <p>${item.data.text}</p>
+                 ${item.videoTime ? `<p class="video-time">From: ${this.formatTime(item.videoTime)}</p>` : ''}
+               </div>
+             `;
+             break;
+             
+           case 'image':
+             itemContent = `
+               ${header}
+               <div class="item-content">
+                 <h3>${item.data.caption || 'Screenshot'}</h3>
+                 <img src="${item.data.url}" alt="${item.data.caption || 'Screenshot'}" />
+                 ${item.videoTime ? `<p class="video-time">From: ${this.formatTime(item.videoTime)}</p>` : ''}
+               </div>
+             `;
+             break;
+             
+           default:
+             itemContent = `
+               ${header}
+               <div class="item-content">
+                 <h3>Saved Item</h3>
+                 <p>Unknown format</p>
+               </div>
+             `;
+         }
+         
+         itemElement.innerHTML = itemContent;
+         
+         // Add event listener for delete button
+         const deleteButton = itemElement.querySelector('.delete-button');
+         if (deleteButton) {
+           deleteButton.addEventListener('click', (e) => {
+             e.stopPropagation();
+             this.deleteItem(item.id);
+           });
+         }
+         
+         itemsContainer.appendChild(itemElement);
+       });
+     }
+     
+     this.container.appendChild(itemsContainer);
+   }
+ }
+ 
+ export default MobileSaver; 
```

---

## 3. Technical Showcase
Let's optimize subtitle processing for near real-time display:

---

```diff
- 
+ const { Readable } = require('stream');
+ const { OpenAI } = require('openai');
+ const WebSocket = require('ws');
+ const ffmpeg = require('fluent-ffmpeg');
+ const ffmpegPath = require('@ffmpeg-installer/ffmpeg').path;
+ const fs = require('fs');
+ const path = require('path');
+ const crypto = require('crypto');
+ const os = require('os');
+ 
+ // Configure ffmpeg path
+ ffmpeg.setFfmpegPath(ffmpegPath);
+ 
+ /**
+  * Optimized Whisper service with streaming and batch processing
+  * for near real-time subtitle generation
+  */
+ class OptimizedWhisperService {
+   constructor(apiKey) {
+     this.openai = new OpenAI({
+       apiKey: apiKey || process.env.OPENAI_API_KEY
+     });
+     
+     // Temporary directory for audio chunks
+     this.tempDir = path.join(os.tmpdir(), 'memorystream-audio');
+     if (!fs.existsSync(this.tempDir)) {
+       fs.mkdirSync(this.tempDir, { recursive: true });
+     }
+     
+     // Subtitle caches for different content
+     this.subtitleCache = new Map();
+     
+     // Active subtitle processing sessions
+     this.activeSessions = new Map();
+     
+     // Cleanup interval
+     this.cleanupInterval = setInterval(() => this.cleanupTempFiles(), 3600000); // 1 hour
+   }
+   
+   /**
+    * Initialize a new streaming subtitle session
+    * @param {string} sessionId - Session identifier
+    * @param {Object} options - Transcription options
+    * @returns {Object} Session information
+    */
+   initSession(sessionId, options = {}) {
+     // Create a unique session key if not provided
+     const session = {
+       id: sessionId || crypto.randomUUID(),
+       options: {
+         language: options.language || 'en',
+         prompt: options.prompt || '',
+         chunkDuration: options.chunkDuration || 10, // seconds
+         model: options.model || 'whisper-1',
+         batchSize: options.batchSize || 3, // process chunks in batches
+         maxWorkers: options.maxWorkers || 2, // parallel API calls
+       },
+       chunks: [],
+       subtitles: [],
+       startTime: Date.now(),
+       lastActivityTime: Date.now(),
+       processingQueue: [],
+       activeWorkers: 0,
+       lastProcessedTime: 0,
+       chunkIndex: 0,
+       isStreaming: true
+     };
+     
+     this.activeSessions.set(session.id, session);
+     
+     return { sessionId: session.id };
+   }
+   
+   /**
+    * Process audio chunk for streaming transcription
+    * @param {string} sessionId - Session identifier
+    * @param {Buffer} audioChunk - Audio data
+    * @param {number} timestamp - Chunk timestamp (in seconds)
+    * @returns {Promise<Object>} Processing status
+    */
+   async processAudioChunk(sessionId, audioChunk, timestamp) {
+     const session = this.activeSessions.get(sessionId);
+     if (!session) {
+       throw new Error(`Session ${sessionId} not found`);
+     }
+     
+     // Update session activity time
+     session.lastActivityTime = Date.now();
+     
+     // Generate a filename for this chunk
+     const chunkFilename = path.join(this.tempDir, 
+       `chunk_${sessionId}_${session.chunkIndex}_${Date.now()}.wav`);
+     session.chunkIndex++;
+     
+     // Convert the audio chunk to WAV format
+     await this.convertAudioToWav(audioChunk, chunkFilename);
+     
+     // Add the chunk to the processing queue
+     const chunk = {
+       filename: chunkFilename,
+       timestamp,
+       index: session.chunkIndex - 1,
+       status: 'queued'
+     };
+     
+     session.chunks.push(chunk);
+     session.processingQueue.push(chunk);
+     
+     // Process the queue if we have enough chunks or enough time has passed
+     if (session.processingQueue.length >= session.options.batchSize || 
+         (timestamp - session.lastProcessedTime > session.options.chunkDuration * 2)) {
+       this.processQueue(sessionId);
+     }
+     
+     return { 
+       status: 'queued', 
+       queueLength: session.processingQueue.length,
+       totalChunks: session.chunks.length 
+     };
+   }
+   
+   /**
+    * Process the queue of audio chunks
+    * @param {string} sessionId - Session identifier
+    */
+   async processQueue(sessionId) {
+     const session = this.activeSessions.get(sessionId);
+     if (!session) return;
+     
+     // If we're already using max workers, wait
+     if (session.activeWorkers >= session.options.maxWorkers) return;
+     
+     // Process chunks in batches to optimize API usage
+     while (session.processingQueue.length > 0 && session.activeWorkers < session.options.maxWorkers) {
+       // Take up to batchSize chunks from the queue for processing
+       const batchSize = Math.min(session.options.batchSize, session.processingQueue.length);
+       const chunkBatch = session.processingQueue.splice(0, batchSize);
+       
+       // Mark these chunks as processing
+       chunkBatch.forEach(chunk => { chunk.status = 'processing'; });
+       
+       // Increment active workers count
+       session.activeWorkers++;
+       
+       // Process the batch asynchronously
+       this.processBatch(sessionId, chunkBatch).finally(() => {
+         // Decrement active workers when done
+         session.activeWorkers--;
+         
+         // Set the last processed time
+         session.lastProcessedTime = Math.max(...chunkBatch.map(c => c.timestamp));
+         
+         // Continue processing if there are more chunks
+         if (session.processingQueue.length > 0) {
+           this.processQueue(sessionId);
+         }
+       });
+     }
+   }
+   
+   /**
+    * Process a batch of audio chunks
+    * @param {string} sessionId - Session identifier
+    * @param {Array} chunkBatch - Batch of audio chunks
+    */
+   async processBatch(sessionId, chunkBatch) {
+     const session = this.activeSessions.get(sessionId);
+     if (!session) return;
+     
+     try {
+       // Sort chunks by timestamp
+       chunkBatch.sort((a, b) => a.timestamp - b.timestamp);
+       
+       // Merge the audio chunks into a single file for more efficient processing
+       const mergedFilename = path.join(this.tempDir, `merged_${sessionId}_${Date.now()}.wav`);
+       await this.mergeAudioFiles(chunkBatch.map(c => c.filename), mergedFilename);
+       
+       // Process the merged file
+       const subtitles = await this.transcribeAudio(mergedFilename, {
+         language: session.options.language,
+         prompt: session.options.prompt,
+         model: session.options.model,
+         response_format: 'vtt',
+         timestamp_granularities: ['segment', 'word']
+       });
+       
+       // Adjust the timestamps based on the first chunk's timestamp
+       const baseTimestamp = chunkBatch[0].timestamp;
+       const adjustedSubtitles = this.adjustSubtitleTimestamps(subtitles, baseTimestamp);
+       
+       // Add the subtitles to the session
+       session.subtitles.push(...adjustedSubtitles);
+       
+       // Sort subtitles by start time
+       session.subtitles.sort((a, b) => a.start - b.start);
+       
+       // Mark chunks as processed
+       chunkBatch.forEach(chunk => { 
+         chunk.status = 'processed'; 
+         
+         // Delete the temp file
+         try {
+           fs.unlinkSync(chunk.filename);
+         } catch (err) {
+           console.error(`Error deleting chunk file ${chunk.filename}:`, err);
+         }
+       });
+       
+       // Delete the merged file
+       try {
+         fs.unlinkSync(mergedFilename);
+       } catch (err) {
+         console.error(`Error deleting merged file ${mergedFilename}:`, err);
+       }
+       
+       // Emit the new subtitles
+       this.emitSubtitles(sessionId, adjustedSubtitles);
+       
+       return adjustedSubtitles;
+     } catch (error) {
+       console.error(`Error processing batch for session ${sessionId}:`, error);
+       
+       // Mark chunks as failed
+       chunkBatch.forEach(chunk => { chunk.status = 'failed'; });
+       
+       throw error;
+     }
+   }
+   
+   /**
+    * Convert audio data to WAV format
+    * @param {Buffer} audioData - Audio data
+    * @param {string} outputFilename - Output filename
+    * @returns {Promise<string>} Output filename
+    */
+   convertAudioToWav(audioData, outputFilename) {
+     return new Promise((resolve, reject) => {
+       // Create a temporary file for the input audio
+       const inputFilename = path.join(this.tempDir, `input_${Date.now()}.raw`);
+       fs.writeFileSync(inputFilename, audioData);
+       
+       // Convert to WAV using ffmpeg
+       ffmpeg(inputFilename)
+         .inputFormat('s16le') // 16-bit signed PCM
+         .audioChannels(1)
+         .audioFrequency(16000)
+         .outputFormat('wav')
+         .on('end', () => {
+           // Delete the temporary input file
+           fs.unlinkSync(inputFilename);
+           resolve(outputFilename);
+         })
+         .on('error', (err) => {
+           // Delete the temporary input file
+           try {
+             fs.unlinkSync(inputFilename);
+           } catch (e) {
+             // Ignore errors
+           }
+           reject(err);
+         })
+         .save(outputFilename);
+     });
+   }
+   
+   /**
+    * Merge multiple audio files into one
+    * @param {Array<string>} inputFiles - Input filenames
+    * @param {string} outputFilename - Output filename
+    * @returns {Promise<string>} Output filename
+    */
+   mergeAudioFiles(inputFiles, outputFilename) {
+     return new Promise((resolve, reject) => {
+       // Create a temporary file list
+       const fileListPath = path.join(this.tempDir, `filelist_${Date.now()}.txt`);
+       const fileListContent = inputFiles.map(file => `file '${file.replace(/'/g, "'\\''")}'`).join('\n');
+       fs.writeFileSync(fileListPath, fileListContent);
+       
+       // Merge files using ffmpeg
+       ffmpeg()
+         .input(fileListPath)
+         .inputFormat('concat')
+         .inputOptions(['-safe 0'])
+         .outputFormat('wav')
+         .audioChannels(1)
+         .audioFrequency(16000)
+         .on('end', () => {
+           // Delete the temporary file list
+           fs.unlinkSync(fileListPath);
+           resolve(outputFilename);
+         })
+         .on('error', (err) => {
+           // Delete the temporary file list
+           try {
+             fs.unlinkSync(fileListPath);
+           } catch (e) {
+             // Ignore errors
+           }
+           reject(err);
+         })
+         .save(outputFilename);
+     });
+   }
+   
+   /**
+    * Transcribe audio file using Whisper
+    * @param {string} audioFile - Audio filename
+    * @param {Object} options - Transcription options
+    * @returns {Promise<Array>} Subtitles
+    */
+   async transcribeAudio(audioFile, options) {
+     try {
+       const transcription = await this.openai.audio.transcriptions.create({
+         file: fs.createReadStream(audioFile),
+         model: options.model,
+         language: options.language,
+         prompt: options.prompt,
+         response_format: options.response_format,
+         timestamp_granularities: options.timestamp_granularities
+       });
+       
+       // Parse VTT content into structured subtitles
+       return this.parseVttContent(transcription);
+     } catch (error) {
+       console.error('Error transcribing audio:', error);
+       throw error;
+     }
+   }
+   
+   /**
+    * Parse VTT content into structured subtitles
+    * @param {string} vttContent - VTT content
+    * @returns {Array} Structured subtitles
+    */
+   parseVttContent(vttContent) {
+     const subtitles = [];
+     const lines = vttContent.split('\n');
+     
+     let currentSubtitle = null;
+     
+     for (let i = 0; i < lines.length; i++) {
+       const line = lines[i].trim();
+       
+       // Skip empty lines and WebVTT header
+       if (!line || line === 'WEBVTT') continue;
+       
+       // Check if it's a timestamp line
+       const timestampRegex = /(\d{2}:\d{2}:\d{2}\.\d{3}) --> (\d{2}:\d{2}:\d{2}\.\d{3})/;
+       const match = line.match(timestampRegex);
+       
+       if (match) {
+         // If we were building a subtitle, push it
+         if (currentSubtitle && currentSubtitle.text) {
+           subtitles.push(currentSubtitle);
+         }
+         
+         // Start a new subtitle
+         currentSubtitle = {
+           start: this.timestampToSeconds(match[1]),
+           end: this.timestampToSeconds(match[2]),
+           text: ''
+         };
+       } else if (currentSubtitle) {
+         // Add text to current subtitle
+         if (currentSubtitle.text) {
+           currentSubtitle.text += ' ' + line;
+         } else {
+           currentSubtitle.text = line;
+         }
+       }
+     }
+     
+     // Add the last subtitle if we have one
+     if (currentSubtitle && currentSubtitle.text) {
+       subtitles.push(currentSubtitle);
+     }
+     
+     return subtitles;
+   }
+   
+   /**
+    * Convert timestamp to seconds
+    * @param {string} timestamp - Timestamp in format HH:MM:SS.mmm
+    * @returns {number} Seconds
+    */
+   timestampToSeconds(timestamp) {
+     const [hours, minutes, seconds] = timestamp.split(':').map(parseFloat);
+     return hours * 3600 + minutes * 60 + seconds;
+   }
+   
+   /**
+    * Convert seconds to timestamp
+    * @param {number} seconds - Seconds
+    * @returns {string} Timestamp in format HH:MM:SS.mmm
+    */
+   secondsToTimestamp(seconds) {
+     const hours = Math.floor(seconds / 3600);
+     const minutes = Math.floor((seconds % 3600) / 60);
+     const secs = seconds % 60;
+     
+     return `${hours.toString().padStart(2, '0')}:${
+       minutes.toString().padStart(2, '0')}:${
+       secs.toFixed(3).padStart(6, '0')}`;
+   }
+   
+   /**
+    * Adjust subtitle timestamps based on a base timestamp
+    * @param {Array} subtitles - Subtitles
+    * @param {number} baseTimestamp - Base timestamp in seconds
+    * @returns {Array} Adjusted subtitles
+    */
+   adjustSubtitleTimestamps(subtitles, baseTimestamp) {
+     return subtitles.map(subtitle => ({
+       ...subtitle,
+       start: subtitle.start + baseTimestamp,
+       end: subtitle.end + baseTimestamp
+     }));
+   }
+   
+   /**
+    * Emit subtitles to connected clients
+    * @param {string} sessionId - Session identifier
+    * @param {Array} subtitles - New subtitles
+    */
+   emitSubtitles(sessionId, subtitles) {
+     // This would be implemented in the main server
+     // where WebSocket connections are managed
+     console.log(`Emitting ${subtitles.length} subtitles for session ${sessionId}`);
+   }
+   
+   /**
+    * Get all subtitles for a session
+    * @param {string} sessionId - Session identifier
+    * @returns {Array} Subtitles
+    */
+   getSubtitles(sessionId) {
+     const session = this.activeSessions.get(sessionId);
+     if (!session) {
+       return [];
+     }
+     
+     return [...session.subtitles].sort((a, b) => a.start - b.start);
+   }
+   
+   /**
+    * Get subtitles for a specific time range
+    * @param {string} sessionId - Session identifier
+    * @param {number} startTime - Start time in seconds
+    * @param {number} endTime - End time in seconds
+    * @returns {Array} Subtitles in range
+    */
+   getSubtitlesInRange(sessionId, startTime, endTime) {
+     const subtitles = this.getSubtitles(sessionId);
+     
+     return subtitles.filter(subtitle => 
+       (subtitle.start >= startTime && subtitle.start <= endTime) ||
+       (subtitle.end >= startTime && subtitle.end <= endTime) ||
+       (subtitle.start <= startTime && subtitle.end >= endTime)
+     );
+   }
+   
+   /**
+    * End a subtitle session
+    * @param {string} sessionId - Session identifier
+    * @returns {Object} Final session state
+    */
+   endSession(sessionId) {
+     const session = this.activeSessions.get(sessionId);
+     if (!session) {
+       throw new Error(`Session ${sessionId} not found`);
+     }
+     
+     // Wait for any in-progress processing to complete
+     if (session.activeWorkers > 0 || session.processingQueue.length > 0) {
+       console.log(`Session ${sessionId} has pending work, waiting before closing...`);
+     }
+     
+     // Get the final subtitles
+     const subtitles = this.getSubtitles(sessionId);
+     
+     // Remove the session
+     this.activeSessions.delete(sessionId);
+     
+     // Clean up any files
+     session.chunks.forEach(chunk => {
+       if (fs.existsSync(chunk.filename)) {
+         try {
+           fs.unlinkSync(chunk.filename);
+         } catch (err) {
+           console.error(`Error deleting chunk file ${chunk.filename}:`, err);
+         }
+       }
+     });
+     
+     return {
+       sessionId,
+       subtitles,
+       duration: (Date.now() - session.startTime) / 1000
+     };
+   }
+   
+   /**
+    * Clean up temporary files
+    */
+   cleanupTempFiles() {
+     // Get all files in the temp directory
+     const files = fs.readdirSync(this.tempDir);
+     const now = Date.now();
+     
+     // Delete files older than 24 hours
+     files.forEach(file => {
+       const filePath = path.join(this.tempDir, file);
+       const stats = fs.statSync(filePath);
+       const fileAge = now - stats.mtimeMs;
+       
+       if (fileAge > 24 * 3600 * 1000) {
+         try {
+           fs.unlinkSync(filePath);
+         } catch (err) {
+           console.error(`Error deleting temp file ${filePath}:`, err);
+         }
+       }
+     });
+   }
+   
+   /**
+    * Stop the service and clean up resources
+    */
+   shutdown() {
+     // Clear the cleanup interval
+     if (this.cleanupInterval) {
+       clearInterval(this.cleanupInterval);
+     }
+     
+     // End all active sessions
+     for (const sessionId of this.activeSessions.keys()) {
+       try {
+         this.endSession(sessionId);
+       } catch (err) {
+         console.error(`Error ending session ${sessionId}:`, err);
+       }
+     }
+     
+     // Final cleanup of temp directory
+     this.cleanupTempFiles();
+   }
+ }
+ 
+ module.exports = OptimizedWhisperService; 
```

---

### Wake Word Detection for Mobile
Let's add local wake word detection to the mobile app:

---

```diff
- 
+ /**
+  * WakeWordDetector.js
+  * Component for local wake word detection to reduce voice command latency
+  */
+ 
+ class WakeWordDetector {
+   constructor(options = {}) {
+     this.options = {
+       wakeWord: options.wakeWord || 'hey memory',
+       threshold: options.threshold || 0.7,
+       maxRecordingTime: options.maxRecordingTime || 5000, // ms
+       processingInterval: options.processingInterval || 500, // ms
+       ...options
+     };
+     
+     this.isListening = false;
+     this.audioContext = null;
+     this.recognizer = null;
+     this.mediaStream = null;
+     this.audioProcessor = null;
+     this.recordingBuffer = [];
+     this.isProcessing = false;
+     this.processingInterval = null;
+     this.onDetectedCallbacks = [];
+     this.onListeningCallbacks = [];
+     this.onErrorCallbacks = [];
+     
+     // Check for browser compatibility
+     this.isCompatible = this.checkCompatibility();
+   }
+ 
+   /**
+    * Check if the browser supports the necessary features
+    * @returns {boolean} Whether the browser is compatible
+    */
+   checkCompatibility() {
+     return !!(
+       window.AudioContext || window.webkitAudioContext ||
+       navigator.mediaDevices?.getUserMedia ||
+       window.SpeechRecognition || window.webkitSpeechRecognition
+     );
+   }
+ 
+   /**
+    * Initialize the wake word detector
+    * @returns {Promise<boolean>} Whether initialization was successful
+    */
+   async init() {
+     if (!this.isCompatible) {
+       this.notifyError('Browser not compatible with wake word detection');
+       return false;
+     }
+     
+     try {
+       // Initialize audio context
+       const AudioContext = window.AudioContext || window.webkitAudioContext;
+       this.audioContext = new AudioContext();
+       
+       // Initialize speech recognition
+       const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
+       this.recognizer = new SpeechRecognition();
+       this.recognizer.continuous = true;
+       this.recognizer.interimResults = true;
+       this.recognizer.lang = 'en-US';
+       
+       // Set up event handlers
+       this.recognizer.onresult = this.handleSpeechResult.bind(this);
+       this.recognizer.onerror = this.handleSpeechError.bind(this);
+       this.recognizer.onend = this.handleSpeechEnd.bind(this);
+       
+       return true;
+     } catch (error) {
+       console.error('Error initializing wake word detector:', error);
+       this.notifyError(`Initialization error: ${error.message}`);
+       return false;
+     }
+   }
+ 
+   /**
+    * Start listening for the wake word
+    * @returns {Promise<boolean>} Whether start was successful
+    */
+   async start() {
+     if (this.isListening) return true;
+     
+     if (!this.audioContext || !this.recognizer) {
+       const initSuccess = await this.init();
+       if (!initSuccess) return false;
+     }
+     
+     try {
+       // Request microphone access
+       this.mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
+       
+       // Connect to audio context
+       const source = this.audioContext.createMediaStreamSource(this.mediaStream);
+       this.audioProcessor = this.audioContext.createScriptProcessor(4096, 1, 1);
+       
+       // Set up audio processing for recording buffer
+       this.audioProcessor.onaudioprocess = (e) => {
+         if (this.isListening) {
+           // Store raw audio data for potential command processing
+           this.recordingBuffer.push(new Float32Array(e.inputBuffer.getChannelData(0)));
+           
+           // Limit buffer size based on maxRecordingTime
+           const bufferDuration = this.recordingBuffer.length * 4096 / this.audioContext.sampleRate * 1000;
+           if (bufferDuration > this.options.maxRecordingTime) {
+             this.recordingBuffer.shift();
+           }
+         }
+       };
+       
+       // Connect the audio graph
+       source.connect(this.audioProcessor);
+       this.audioProcessor.connect(this.audioContext.destination);
+       
+       // Start speech recognition
+       this.recognizer.start();
+       
+       // Start periodic processing
+       this.processingInterval = setInterval(() => {
+         this.processAudioBuffer();
+       }, this.options.processingInterval);
+       
+       this.isListening = true;
+       this.notifyListeningChange(true);
+       
+       return true;
+     } catch (error) {
+       console.error('Error starting wake word detector:', error);
+       this.notifyError(`Start error: ${error.message}`);
+       return false;
+     }
+   }
+ 
+   /**
+    * Stop listening for the wake word
+    */
+   stop() {
+     if (!this.isListening) return;
+     
+     try {
+       // Stop speech recognition
+       if (this.recognizer) {
+         this.recognizer.stop();
+       }
+       
+       // Stop audio processing
+       if (this.audioProcessor) {
+         this.audioProcessor.disconnect();
+         this.audioProcessor = null;
+       }
+       
+       // Stop media stream
+       if (this.mediaStream) {
+         this.mediaStream.getTracks().forEach(track => track.stop());
+         this.mediaStream = null;
+       }
+       
+       // Clear processing interval
+       if (this.processingInterval) {
+         clearInterval(this.processingInterval);
+         this.processingInterval = null;
+       }
+       
+       // Clear recording buffer
+       this.recordingBuffer = [];
+       this.isProcessing = false;
+       this.isListening = false;
+       this.notifyListeningChange(false);
+     } catch (error) {
+       console.error('Error stopping wake word detector:', error);
+       this.notifyError(`Stop error: ${error.message}`);
+     }
+   }
+ 
+   /**
+    * Handle speech recognition results
+    * @param {Event} event - Speech recognition event
+    */
+   handleSpeechResult(event) {
+     if (!this.isListening || !event.results) return;
+     
+     const result = event.results[event.results.length - 1];
+     if (!result.isFinal) {
+       const transcript = result[0].transcript.trim().toLowerCase();
+       
+       // Check if the transcript contains the wake word
+       if (transcript.includes(this.options.wakeWord) && result[0].confidence >= this.options.threshold) {
+         this.handleWakeWordDetected(transcript);
+       }
+     }
+   }
+ 
+   /**
+    * Handle speech recognition errors
+    * @param {Event} event - Speech recognition error event
+    */
+   handleSpeechError(event) {
+     console.warn('Speech recognition error:', event.error);
+     
+     // Some errors are non-fatal, just notify
+     this.notifyError(`Recognition error: ${event.error}`);
+     
+     // If we get a fatal error, restart recognition
+     if (['network', 'service-not-allowed'].includes(event.error)) {
+       // Wait a bit before restarting
+       setTimeout(() => {
+         if (this.isListening) {
+           this.stop();
+           this.start();
+         }
+       }, 3000);
+     }
+   }
+ 
+   /**
+    * Handle speech recognition end
+    */
+   handleSpeechEnd() {
+     // Speech recognition can end unexpectedly, restart if we're still supposed to be listening
+     if (this.isListening && this.recognizer) {
+       try {
+         this.recognizer.start();
+       } catch (error) {
+         console.warn('Error restarting speech recognition:', error);
+         
+         // If we can't restart immediately, try again after a delay
+         setTimeout(() => {
+           if (this.isListening) {
+             try {
+               this.recognizer.start();
+             } catch (e) {
+               // If it fails again, give up and stop properly
+               this.stop();
+               this.notifyError('Failed to restart speech recognition');
+             }
+           }
+         }, 1000);
+       }
+     }
+   }
+ 
+   /**
+    * Handle wake word detection
+    * @param {string} transcript - Detected speech transcript
+    */
+   handleWakeWordDetected(transcript) {
+     // Notify listeners of wake word detection
+     this.notifyDetection(transcript);
+     
+     // Process the audio buffer to provide the recent audio for command processing
+     // This allows for lower latency as we already have the audio data
+     const recordingData = this.getRecordingBuffer();
+     
+     // Stop listening temporarily to avoid recursive detections
+     this.stop();
+     
+     // Notify with the recording data
+     this.notifyDetection(transcript, recordingData);
+   }
+ 
+   /**
+    * Process the audio buffer for wake word detection
+    * Alternative to using the speech recognition API
+    */
+   processAudioBuffer() {
+     // This is a placeholder for more sophisticated wake word detection
+     // In a real implementation, this would use a local model (e.g., TensorFlow.js)
+     // to detect the wake word in the audio buffer
+     
+     // For now, we rely primarily on the speech recognition API
+     if (this.isProcessing || this.recordingBuffer.length === 0) return;
+     
+     this.isProcessing = true;
+     
+     // Example of how we might process the buffer:
+     // 1. Convert raw audio to the format needed by our model
+     // 2. Run the wake word detection model on the processed audio
+     // 3. If wake word detected with sufficient confidence, trigger the callback
+     
+     this.isProcessing = false;
+   }
+ 
+   /**
+    * Get the current recording buffer as a single audio buffer
+    * @returns {Float32Array} Concatenated audio buffer
+    */
+   getRecordingBuffer() {
+     if (this.recordingBuffer.length === 0) return new Float32Array(0);
+     
+     // Calculate total length
+     const totalLength = this.recordingBuffer.reduce(
+       (sum, buffer) => sum + buffer.length, 0
+     );
+     
+     // Create a new buffer and copy data
+     const result = new Float32Array(totalLength);
+     let offset = 0;
+     
+     for (const buffer of this.recordingBuffer) {
+       result.set(buffer, offset);
+       offset += buffer.length;
+     }
+     
+     return result;
+   }
+ 
+   /**
+    * Register a callback for wake word detection
+    * @param {Function} callback - Callback function
+    */
+   onDetected(callback) {
+     if (typeof callback === 'function') {
+       this.onDetectedCallbacks.push(callback);
+     }
+   }
+ 
+   /**
+    * Register a callback for listening state changes
+    * @param {Function} callback - Callback function
+    */
+   onListeningChange(callback) {
+     if (typeof callback === 'function') {
+       this.onListeningCallbacks.push(callback);
+     }
+   }
+ 
+   /**
+    * Register a callback for errors
+    * @param {Function} callback - Callback function
+    */
+   onError(callback) {
+     if (typeof callback === 'function') {
+       this.onErrorCallbacks.push(callback);
+     }
+   }
+ 
+   /**
+    * Notify all detection callbacks
+    * @param {string} transcript - Detected speech transcript
+    * @param {Float32Array} audioData - Raw audio data
+    */
+   notifyDetection(transcript, audioData) {
+     const data = {
+       timestamp: Date.now(),
+       transcript,
+       audioData,
+       wakeWord: this.options.wakeWord
+     };
+     
+     this.onDetectedCallbacks.forEach(callback => {
+       try {
+         callback(data);
+       } catch (error) {
+         console.error('Error in wake word detection callback:', error);
+       }
+     });
+   }
+ 
+   /**
+    * Notify all listening change callbacks
+    * @param {boolean} isListening - Whether the detector is now listening
+    */
+   notifyListeningChange(isListening) {
+     this.onListeningCallbacks.forEach(callback => {
+       try {
+         callback(isListening);
+       } catch (error) {
+         console.error('Error in listening change callback:', error);
+       }
+     });
+   }
+ 
+   /**
+    * Notify all error callbacks
+    * @param {string} message - Error message
+    */
+   notifyError(message) {
+     const error = {
+       timestamp: Date.now(),
+       message
+     };
+     
+     this.onErrorCallbacks.forEach(callback => {
+       try {
+         callback(error);
+       } catch (err) {
+         console.error('Error in error callback:', err);
+       }
+     });
+   }
+ 
+   /**
+    * Set a new wake word
+    * @param {string} wakeWord - New wake word
+    */
+   setWakeWord(wakeWord) {
+     if (!wakeWord) return;
+     this.options.wakeWord = wakeWord.toLowerCase();
+   }
+ 
+   /**
+    * Clean up resources
+    */
+   destroy() {
+     this.stop();
+     
+     if (this.audioContext) {
+       this.audioContext.close();
+       this.audioContext = null;
+     }
+     
+     this.recognizer = null;
+     this.onDetectedCallbacks = [];
+     this.onListeningCallbacks = [];
+     this.onErrorCallbacks = [];
+   }
+ }
+ 
+ export default WakeWordDetector; 
```

---

### Adaptive Streaming Quality
Let's implement adaptive streaming quality based on connection speed:

---

```diff
- 
+ /**
+  * AdaptiveStreamingManager.js
+  * Component for managing adaptive streaming quality based on connection speed
+  */
+ 
+ class AdaptiveStreamingManager {
+   constructor(videoPlayer, options = {}) {
+     this.videoPlayer = videoPlayer;
+     this.options = {
+       // Thresholds in Kbps
+       qualityThresholds: {
+         low: 1000,    // 1 Mbps
+         medium: 5000,  // 5 Mbps
+         high: 10000    // 10 Mbps
+       },
+       // Default ABR (Adaptive Bitrate) strategy
+       defaultAbrStrategy: 'auto',
+       // Network speed test interval in ms
+       speedTestInterval: 30000, // 30 seconds
+       // Initial ABR strategy
+       initialAbrStrategy: 'bandwidth',
+       // Enable advanced metrics collection
+       enableMetrics: true,
+       // Override with provided options
+       ...options
+     };
+     
+     // Network state
+     this.networkState = {
+       lastSpeedMeasurement: 0,
+       lastMeasurementTime: 0,
+       averageSpeed: 0,
+       measurements: [],
+       connectionType: 'unknown',
+       isMetered: false
+     };
+     
+     // Quality settings
+     this.currentQuality = 'auto';
+     this.preferredQuality = 'auto';
+     this.isAdaptiveEnabled = true;
+     
+     // Monitoring intervals
+     this.speedTestIntervalId = null;
+     this.networkMonitoringEnabled = false;
+     
+     // Performance metrics
+     this.metrics = {
+       bufferingEvents: 0,
+       qualitySwitches: 0,
+       bufferingDuration: 0,
+       lastBufferingEvent: 0,
+       initialLoadTime: 0,
+       rebufferingRatio: 0,
+       bandwidthEstimates: []
+     };
+     
+     // Cache for stream ABR settings
+     this.streamConfigurations = new Map();
+     
+     // Bind methods
+     this.updateNetworkInformation = this.updateNetworkInformation.bind(this);
+     this.handleBufferingStart = this.handleBufferingStart.bind(this);
+     this.handleBufferingEnd = this.handleBufferingEnd.bind(this);
+     this.handleQualityChange = this.handleQualityChange.bind(this);
+   }
+ 
+   /**
+    * Initialize the adaptive streaming manager
+    */
+   init() {
+     // Set up event listeners
+     this.setupEventListeners();
+     
+     // Initialize network information
+     this.updateNetworkInformation();
+     
+     // Start network monitoring
+     this.startNetworkMonitoring();
+     
+     // Configure initial ABR strategy
+     this.configureAbrStrategy(this.options.initialAbrStrategy);
+     
+     // Set up speed test interval
+     this.speedTestIntervalId = setInterval(() => {
+       this.measureConnectionSpeed();
+     }, this.options.speedTestInterval);
+     
+     console.log('AdaptiveStreamingManager initialized');
+   }
+ 
+   /**
+    * Set up event listeners for video and network events
+    */
+   setupEventListeners() {
+     // Listen for player events
+     if (this.videoPlayer) {
+       // Shaka player events
+       if (this.videoPlayer.player) {
+         this.videoPlayer.player.addEventListener('buffering', (event) => {
+           if (event.buffering) {
+             this.handleBufferingStart();
+           } else {
+             this.handleBufferingEnd();
+           }
+         });
+         
+         this.videoPlayer.player.addEventListener('adaptation', this.handleQualityChange);
+       }
+       
+       // HTML5 video element events
+       if (this.videoPlayer.video) {
+         this.videoPlayer.video.addEventListener('waiting', this.handleBufferingStart);
+         this.videoPlayer.video.addEventListener('playing', this.handleBufferingEnd);
+       }
+     }
+     
+     // Network information events
+     if (navigator.connection) {
+       navigator.connection.addEventListener('change', this.updateNetworkInformation);
+     }
+     
+     // Window online/offline events
+     window.addEventListener('online', this.updateNetworkInformation);
+     window.addEventListener('offline', this.updateNetworkInformation);
+   }
+ 
+   /**
+    * Start monitoring network conditions
+    */
+   startNetworkMonitoring() {
+     if (this.networkMonitoringEnabled) return;
+     
+     this.networkMonitoringEnabled = true;
+     
+     // Perform initial speed measurement
+     this.measureConnectionSpeed();
+   }
+ 
+   /**
+    * Stop monitoring network conditions
+    */
+   stopNetworkMonitoring() {
+     this.networkMonitoringEnabled = false;
+     
+     if (this.speedTestIntervalId) {
+       clearInterval(this.speedTestIntervalId);
+       this.speedTestIntervalId = null;
+     }
+   }
+ 
+   /**
+    * Update network information from navigator.connection
+    */
+   updateNetworkInformation() {
+     const connection = navigator.connection || navigator.mozConnection || navigator.webkitConnection;
+     
+     if (connection) {
+       this.networkState.connectionType = connection.type || 'unknown';
+       this.networkState.isMetered = connection.metered || false;
+       
+       // If downlink speed is available, use it
+       if (connection.downlink) {
+         // Convert Mbps to Kbps
+         const speedKbps = connection.downlink * 1000;
+         this.updateSpeedMeasurement(speedKbps);
+       }
+       
+       // If the connection is slow or metered, adjust quality accordingly
+       if (connection.saveData) {
+         this.setQuality('low');
+       } else if (connection.effectiveType === '2g' || connection.effectiveType === 'slow-2g') {
+         this.setQuality('low');
+       } else if (connection.effectiveType === '3g') {
+         this.setQuality('medium');
+       }
+     }
+     
+     // If we're offline, handle it
+     if (!navigator.onLine) {
+       this.handleOfflineMode();
+     }
+     
+     console.log('Network information updated:', this.networkState);
+   }
+ 
+   /**
+    * Measure current connection speed
+    * @returns {Promise<number>} Connection speed in Kbps
+    */
+   async measureConnectionSpeed() {
+     if (!this.networkMonitoringEnabled || !navigator.onLine) return 0;
+     
+     try {
+       const startTime = Date.now();
+       // Use a small image from a CDN for speed testing
+       const testImageUrl = `https://cdn.jsdelivr.net/gh/Automattic/node-canvas/test/fixtures/cat.png?nocache=${startTime}`;
+       
+       const response = await fetch(testImageUrl, { mode: 'cors', cache: 'no-store' });
+       const data = await response.blob();
+       const endTime = Date.now();
+       
+       // Calculate speed in kilobits per second
+       const durationSeconds = (endTime - startTime) / 1000;
+       const fileSizeBits = data.size * 8;
+       const speedKbps = (fileSizeBits / durationSeconds) / 1000;
+       
+       this.updateSpeedMeasurement(speedKbps);
+       this.adjustQualityBasedOnSpeed(speedKbps);
+       
+       return speedKbps;
+     } catch (error) {
+       console.error('Error measuring connection speed:', error);
+       return 0;
+     }
+   }
+ 
+   /**
+    * Update speed measurement history and average
+    * @param {number} speedKbps - Speed in Kbps
+    */
+   updateSpeedMeasurement(speedKbps) {
+     const now = Date.now();
+     this.networkState.lastSpeedMeasurement = speedKbps;
+     this.networkState.lastMeasurementTime = now;
+     
+     // Add to measurements array (keep last 5)
+     this.networkState.measurements.push({
+       speed: speedKbps,
+       timestamp: now
+     });
+     
+     // Keep only the last 5 measurements
+     if (this.networkState.measurements.length > 5) {
+       this.networkState.measurements.shift();
+     }
+     
+     // Calculate average speed
+     this.networkState.averageSpeed = this.networkState.measurements.reduce(
+       (sum, measurement) => sum + measurement.speed, 0
+     ) / this.networkState.measurements.length;
+     
+     // Record for metrics
+     if (this.options.enableMetrics) {
+       this.metrics.bandwidthEstimates.push({
+         timestamp: now,
+         bandwidth: speedKbps
+       });
+       
+       // Keep metrics history manageable
+       if (this.metrics.bandwidthEstimates.length > 20) {
+         this.metrics.bandwidthEstimates.shift();
+       }
+     }
+   }
+ 
+   /**
+    * Adjust streaming quality based on measured speed
+    * @param {number} speedKbps - Speed in Kbps
+    */
+   adjustQualityBasedOnSpeed(speedKbps) {
+     if (!this.isAdaptiveEnabled) return;
+     
+     const { qualityThresholds } = this.options;
+     
+     let targetQuality;
+     if (speedKbps < qualityThresholds.low) {
+       targetQuality = 'low';
+     } else if (speedKbps < qualityThresholds.medium) {
+       targetQuality = 'medium';
+     } else if (speedKbps < qualityThresholds.high) {
+       targetQuality = 'high';
+     } else {
+       targetQuality = 'auto';
+     }
+     
+     // Only change if different from current quality
+     if (targetQuality !== this.currentQuality) {
+       this.setQuality(targetQuality);
+     }
+   }
+ 
+   /**
+    * Handle offline mode
+    */
+   handleOfflineMode() {
+     console.log('Device is offline, adjusting playback settings');
+     
+     // Set quality to lowest to conserve data when connection returns
+     this.setQuality('low');
+     
+     // If we have a player, pause it if playing
+     if (this.videoPlayer && this.videoPlayer.video && !this.videoPlayer.video.paused) {
+       this.videoPlayer.pause();
+     }
+   }
+ 
+   /**
+    * Set streaming quality
+    * @param {string} quality - Quality level (low, medium, high, auto)
+    */
+   setQuality(quality) {
+     if (!this.videoPlayer || !this.videoPlayer.player) return;
+     
+     this.currentQuality = quality;
+     
+     // Configure Shaka player based on quality
+     const player = this.videoPlayer.player;
+     const config = { abr: {}, streaming: {} };
+     
+     switch (quality) {
+       case 'low':
+         config.abr.enabled = false;
+         config.streaming.preferredVideoQuality = 360; // Prefer 360p
+         config.streaming.maxHeight = 480; // Cap at 480p
+         config.streaming.bufferingGoal = 15; // Increase buffer (15 seconds)
+         break;
+         
+       case 'medium':
+         config.abr.enabled = true;
+         config.abr.restrictToScreenSize = true;
+         config.streaming.preferredVideoQuality = 720; // Prefer 720p
+         config.streaming.maxHeight = 720; // Cap at 720p
+         config.streaming.bufferingGoal = 10; // Standard buffer
+         break;
+         
+       case 'high':
+         config.abr.enabled = true;
+         config.streaming.preferredVideoQuality = 1080; // Prefer 1080p
+         config.streaming.maxHeight = 1440; // Allow up to 1440p
+         config.streaming.bufferingGoal = 6; // Lower buffer for high bandwidth
+         break;
+         
+       case 'auto':
+       default:
+         config.abr.enabled = true;
+         config.abr.restrictToScreenSize = false;
+         config.streaming.preferredVideoQuality = null; // No preference
+         config.streaming.maxHeight = null; // No cap
+         config.streaming.bufferingGoal = 10; // Standard buffer
+         break;
+     }
+     
+     // Apply configuration
+     player.configure(config);
+     
+     console.log(`Streaming quality set to ${quality}`);
+     
+     // Record quality change in metrics
+     if (this.options.enableMetrics) {
+       this.metrics.qualitySwitches++;
+     }
+   }
+ 
+   /**
+    * Configure ABR (Adaptive Bitrate) strategy
+    * @param {string} strategy - ABR strategy (bandwidth, buffer, auto)
+    */
+   configureAbrStrategy(strategy) {
+     if (!this.videoPlayer || !this.videoPlayer.player) return;
+     
+     const player = this.videoPlayer.player;
+     const config = { abr: {} };
+     
+     switch (strategy) {
+       case 'bandwidth':
+         // Prioritize bandwidth estimation
+         config.abr.enabled = true;
+         config.abr.bandwidthEstimate = this.networkState.averageSpeed * 1000; // Convert to bps
+         config.abr.switchInterval = 8; // Faster switching
+         config.abr.safetyFactor = 0.8; // 80% of estimated bandwidth
+         break;
+         
+       case 'buffer':
+         // Prioritize stable buffer levels
+         config.abr.enabled = true;
+         config.abr.switchInterval = 10; // Normal switching
+         config.abr.safetyFactor = 0.9; // 90% of estimated bandwidth
+         break;
+         
+       case 'auto':
+       default:
+         // Default Shaka behavior
+         config.abr.enabled = true;
+         config.abr.switchInterval = 8;
+         config.abr.safetyFactor = 0.85;
+         break;
+     }
+     
+     // Apply configuration
+     player.configure(config);
+     
+     console.log(`ABR strategy set to ${strategy}`);
+   }
+ 
+   /**
+    * Handle buffering start event
+    */
+   handleBufferingStart() {
+     if (!this.options.enableMetrics) return;
+     
+     const now = Date.now();
+     this.metrics.bufferingEvents++;
+     this.metrics.lastBufferingEvent = now;
+     
+     // Check if we should adjust quality due to buffering
+     if (this.metrics.bufferingEvents > 3 && this.currentQuality !== 'low') {
+       // Multiple buffering events, reduce quality
+       const previousQuality = this.currentQuality;
+       if (previousQuality === 'high') {
+         this.setQuality('medium');
+       } else if (previousQuality === 'medium' || previousQuality === 'auto') {
+         this.setQuality('low');
+       }
+       
+       console.log(`Reducing quality due to buffering: ${previousQuality} -> ${this.currentQuality}`);
+     }
+   }
+ 
+   /**
+    * Handle buffering end event
+    */
+   handleBufferingEnd() {
+     if (!this.options.enableMetrics) return;
+     
+     const now = Date.now();
+     
+     // Calculate buffering duration if we have a start time
+     if (this.metrics.lastBufferingEvent > 0) {
+       const bufferingTime = now - this.metrics.lastBufferingEvent;
+       this.metrics.bufferingDuration += bufferingTime;
+       
+       // Calculate rebuffering ratio
+       const videoElement = this.videoPlayer.video;
+       if (videoElement) {
+         const playbackTime = videoElement.currentTime;
+         if (playbackTime > 0) {
+           this.metrics.rebufferingRatio = this.metrics.bufferingDuration / (playbackTime * 1000);
+         }
+       }
+     }
+   }
+ 
+   /**
+    * Handle quality change event
+    * @param {Event} event - Quality change event
+    */
+   handleQualityChange(event) {
+     if (!this.options.enableMetrics) return;
+     
+     // Record quality switch
+     this.metrics.qualitySwitches++;
+     
+     console.log('Quality changed:', event);
+   }
+ 
+   /**
+    * Save stream configuration for a specific content
+    * @param {string} contentId - Content identifier
+    */
+   saveStreamConfiguration(contentId) {
+     if (!contentId) return;
+     
+     const configuration = {
+       quality: this.currentQuality,
+       timestamp: Date.now(),
+       networkState: { ...this.networkState }
+     };
+     
+     this.streamConfigurations.set(contentId, configuration);
+   }
+ 
+   /**
+    * Load stream configuration for a specific content
+    * @param {string} contentId - Content identifier
+    * @returns {boolean} Whether configuration was loaded
+    */
+   loadStreamConfiguration(contentId) {
+     if (!contentId || !this.streamConfigurations.has(contentId)) return false;
+     
+     const configuration = this.streamConfigurations.get(contentId);
+     
+     // Only use saved configuration if it's recent (less than 1 hour old)
+     const isRecent = (Date.now() - configuration.timestamp) < 3600000;
+     
+     if (isRecent) {
+       this.setQuality(configuration.quality);
+       return true;
+     }
+     
+     return false;
+   }
+ 
+   /**
+    * Set preferred quality (user override)
+    * @param {string} quality - Quality level
+    */
+   setPreferredQuality(quality) {
+     this.preferredQuality = quality;
+     
+     // If preferred quality is not 'auto', disable adaptive behavior
+     this.isAdaptiveEnabled = (quality === 'auto');
+     
+     // Apply the quality setting
+     this.setQuality(quality);
+   }
+ 
+   /**
+    * Get current streaming metrics
+    * @returns {Object} Streaming metrics
+    */
+   getMetrics() {
+     if (!this.options.enableMetrics) return null;
+     
+     // Add current player stats if available
+     if (this.videoPlayer && this.videoPlayer.player) {
+       const stats = this.videoPlayer.player.getStats();
+       this.metrics.currentStats = stats;
+     }
+     
+     return { ...this.metrics };
+   }
+ 
+   /**
+    * Get current quality
+    * @returns {string} Current quality level
+    */
+   getCurrentQuality() {
+     return this.currentQuality;
+   }
+ 
+   /**
+    * Get estimated bandwidth
+    * @returns {number} Estimated bandwidth in Kbps
+    */
+   getEstimatedBandwidth() {
+     return this.networkState.averageSpeed;
+   }
+ 
+   /**
+    * Reset metrics
+    */
+   resetMetrics() {
+     this.metrics = {
+       bufferingEvents: 0,
+       qualitySwitches: 0,
+       bufferingDuration: 0,
+       lastBufferingEvent: 0,
+       initialLoadTime: 0,
+       rebufferingRatio: 0,
+       bandwidthEstimates: []
+     };
+   }
+ 
+   /**
+    * Clean up resources
+    */
+   destroy() {
+     this.stopNetworkMonitoring();
+     
+     // Remove event listeners
+     if (this.videoPlayer && this.videoPlayer.player) {
+       this.videoPlayer.player.removeEventListener('buffering');
+       this.videoPlayer.player.removeEventListener('adaptation');
+     }
+     
+     if (this.videoPlayer && this.videoPlayer.video) {
+       this.videoPlayer.video.removeEventListener('waiting', this.handleBufferingStart);
+       this.videoPlayer.video.removeEventListener('playing', this.handleBufferingEnd);
+     }
+     
+     if (navigator.connection) {
+       navigator.connection.removeEventListener('change', this.updateNetworkInformation);
+     }
+     
+     window.removeEventListener('online', this.updateNetworkInformation);
+     window.removeEventListener('offline', this.updateNetworkInformation);
+   }
+ }
+ 
+ export default AdaptiveStreamingManager; 
```

---

Now let's update the backend package.json to include the new dependencies needed for these enhancements:

---

Read file: backend/package.json

---

```diff
    },
    "dependencies": {
+     "@ffmpeg-installer/ffmpeg": "^1.1.0",
+     "axios": "^1.6.0",
      "cors": "^2.8.5",
+     "crypto": "^1.0.1",
      "dotenv": "^16.3.1",
      "express": "^4.18.2",
+     "fluent-ffmpeg": "^2.1.2",
+     "node-cache": "^5.1.2",
      "openai": "^4.17.4",
      "qrcode": "^1.5.3",
      "redis": "^4.6.10",
      "socket.io": "^4.7.2",
-     "uuid": "^9.0.1"
+     "uuid": "^9.0.1",
+     "ws": "^8.14.2"
    },
    "devDependencies": {
```

---

Let's now update the mobile app's package.json to include the necessary dependencies for wake word detection:

---

Read file: mobile-app/package.json

---

```diff
      "socket.io-client": "^4.7.2",
      "qrcode-parser": "^1.0.0",
-     "workbox-window": "^7.0.0"
+     "workbox-window": "^7.0.0",
+     "@tensorflow/tfjs": "^4.12.0",
+     "@tensorflow-models/speech-commands": "^0.5.4",
+     "detect-browser": "^5.3.0",
+     "dexie": "^3.2.4",
+     "recordrtc": "^5.6.2",
+     "localforage": "^1.10.0"
    },
    "devDependencies": {
```

---

Let's also update the TV app's package.json to include the dependencies needed for adaptive streaming:

---

Read file: tv-app/package.json

---

```diff
      "qrcode": "^1.5.3",
      "shaka-player": "^4.3.6",
-     "socket.io-client": "^4.7.2"
+     "socket.io-client": "^4.7.2",
+     "dashjs": "^4.7.2",
+     "hls.js": "^1.4.12",
+     "fast-webp": "^2.0.5",
+     "web-vitals": "^3.4.0"
    },
    "devDependencies": {
```

---

Now I'll create a system integration plan that describes how all these components work together:

---

```diff
- 
+ # MemoryStream Enhanced Features Integration Guide
+ 
+ This document outlines how the enhanced features are integrated into the MemoryStream application architecture.
+ 
+ ## 1. Enhanced Intelligence Features
+ 
+ ### Content Recognition
+ 
+ The content recognition system automatically identifies shows and movies being watched:
+ 
+ 1. `ContentRecognitionService.js` in the backend analyzes dialogue text from the subtitle stream
+ 2. It extracts potential movie/show titles and character names
+ 3. It queries TMDB API to find matching content
+ 4. When content is identified, the system:
+    - Displays content information in the TV UI
+    - Provides context for the AI assistant for more informative responses
+    - Enables personalized recommendations
+ 
+ **Data Flow:**
+ ```
+ Audio â†’ Whisper â†’ TranscribedText â†’ ContentRecognitionService â†’ TMDB API â†’ ContentMetadata
+ ```
+ 
+ ### Scene-Based Context
+ 
+ The scene analysis system provides understanding of what's happening on screen:
+ 
+ 1. `SceneAnalysisService.js` captures frames from the video at regular intervals
+ 2. Frames are sent to OpenAI's Vision model for analysis
+ 3. The system identifies characters, actions, settings and objects
+ 4. This information is aggregated to build a continuous scene understanding
+ 5. Used to provide context for questions about visual elements not mentioned in dialogue
+ 
+ **Data Flow:**
+ ```
+ VideoFrames â†’ SceneAnalysisService â†’ GPT-4 Vision â†’ SceneContext â†’ Enhanced QA
+ ```
+ 
+ ### Personalized Recommendations
+ 
+ The recommendation engine delivers content suggestions based on viewing history and interactions:
+ 
+ 1. `RecommendationService.js` tracks user interactions with content
+ 2. It builds user preference profiles for genres, actors, etc.
+ 3. It generates recommendations using:
+    - TMDB similar content API
+    - User preference matching with available content
+    - GPT-4 for context-aware recommendations
+ 4. Recommendations are displayed in the TV UI and can be saved to mobile
+ 
+ **Data Flow:**
+ ```
+ UserInteractions â†’ RecommendationService â†’ UserProfiles â†’ TMDB + GPT-4 â†’ Recommendations
+ ```
+ 
+ ## 2. Multi-Device Experience
+ 
+ ### Shared Viewing with Synchronized Playback
+ 
+ Enables multiple viewers to share a synchronized viewing experience:
+ 
+ 1. `SharedViewingService.js` manages viewing sessions
+ 2. Host creates a session and generates a join code
+ 3. Other users join the session by entering the code
+ 4. The service synchronizes playback state across all devices
+ 5. WebSocket connections maintain real-time communication
+ 
+ **Implementation Details:**
+ - Session state is maintained on the server
+ - State changes are broadcast to all connected clients
+ - Syncing algorithm accounts for network latency
+ - Host has playback control by default, but can grant it to others
+ 
+ ### Collaborative Q&A
+ 
+ Allows multiple users to ask and answer questions about the content:
+ 
+ 1. Questions are submitted through the mobile app
+ 2. Questions are shared with all session participants
+ 3. Anyone can provide answers or "like" existing answers
+ 4. AI can also provide answers based on the dialogue context
+ 5. Questions and answers are persisted for the session
+ 
+ **User Flow:**
+ - User asks question via mobile app
+ - Question appears on all connected devices
+ - Others can contribute answers
+ - Question appears with timestamp related to video content
+ - Users can navigate to specific points in video from questions
+ 
+ ### "Send to Mobile" Functionality
+ 
+ Lets users save content from TV to their mobile device:
+ 
+ 1. `MobileSaver.js` component on mobile receives saved items
+ 2. TV app can send various types of content:
+    - Links to related content
+    - Timestamps with notes
+    - Screenshots/images
+    - Information about actors, characters, etc.
+ 3. Items are stored locally on the mobile device
+ 
+ **Implementation Details:**
+ - Uses WebSocket for sending data from TV to mobile
+ - LocalStorage/IndexedDB for persistent storage on mobile
+ - Custom notification system for new items
+ 
+ ## 3. Technical Showcases
+ 
+ ### Near Real-Time Subtitle Processing
+ 
+ Optimized subtitle generation system:
+ 
+ 1. `OptimizedWhisperService.js` processes audio in small chunks
+ 2. Uses batch processing to optimize API usage
+ 3. Multiple chunks are merged for better context
+ 4. Parallel processing with worker limits for efficiency
+ 5. Results streamed back to clients as soon as available
+ 
+ **Optimization Techniques:**
+ - Audio chunking and merging
+ - Batch processing to reduce API calls
+ - Caching of recent results
+ - Adjustable processing parameters
+ 
+ ### Local Wake Word Detection
+ 
+ Reduces latency for voice commands:
+ 
+ 1. `WakeWordDetector.js` runs entirely on the mobile device
+ 2. Uses the Web Speech API with fallback to TensorFlow.js models
+ 3. Continuously listens for the wake word ("hey memory")
+ 4. When detected, activates full voice command mode
+ 5. Maintains a buffer of recent audio to reduce initial processing delay
+ 
+ **Technical Implementation:**
+ - WebAudio API for audio processing
+ - Web Speech API for primary detection
+ - RecordRTC for audio recording
+ - TensorFlow.js as an optional detection method
+ 
+ ### Adaptive Streaming Quality
+ 
+ Optimizes video quality based on network conditions:
+ 
+ 1. `AdaptiveStreamingManager.js` integrates with the video player
+ 2. Monitors network connection quality and stability
+ 3. Adjusts streaming parameters in real-time:
+    - Resolution (height/width)
+    - Bitrate
+    - Buffer size
+ 4. Handles network changes and interruptions gracefully
+ 
+ **Key Features:**
+ - Real-time bandwidth measurement
+ - Quality level thresholds (low, medium, high, auto)
+ - Connection monitoring (type, speed, metered status)
+ - Fallback mechanisms for offline/limited connectivity
+ 
+ ## System Integration
+ 
+ These features integrate within the existing architecture:
+ 
+ 1. **Backend Integration:**
+    - New services are added to the backend server
+    - Services communicate via events and shared state
+    - WebSocket handlers are extended to support new message types
+ 
+ 2. **TV App Integration:**
+    - VideoPlayer component is enhanced with adaptive streaming
+    - UI updated to display content recognition results
+    - New UI elements for session management and collaborative features
+ 
+ 3. **Mobile App Integration:**
+    - New tabs for saved items and shared viewing
+    - Background wake word detection
+    - Collaborative Q&A interface
+ 
+ 4. **Cross-Component Communication:**
+    - WebSockets for real-time communication
+    - Shared session state
+    - Content IDs used as common references
+ 
+ ## Deployment Considerations
+ 
+ 1. **Performance Optimization:**
+    - Caching strategies for recognized content and recommendations
+    - Efficient buffer management for streaming
+    - Battery usage optimization for wake word detection
+ 
+ 2. **Scalability:**
+    - Shared viewing sessions can be distributed across server instances
+    - Whisper API usage is optimized through batching
+    - Content recognition results are cached
+ 
+ 3. **Monitoring:**
+    - Key metrics for tracking system health:
+      - Subtitle processing latency
+      - Streaming adaptation frequency
+      - Session synchronization accuracy
+      - Wake word detection precision
+ 
+ ## Future Enhancements
+ 
+ Potential areas for future development:
+ 
+ 1. **Enhanced Intelligence:**
+    - Full video understanding (not just frames)
+    - Actor identification with face recognition
+    - Extended content database beyond TMDB
+ 
+ 2. **Multi-Device Experience:**
+    - Screen mirroring for companion content
+    - Multi-room synchronized playback
+    - Cross-device persistent viewing history
+ 
+ 3. **Technical Improvements:**
+    - Fully local subtitle generation
+    - Customizable wake words and voice models
+    - HDR and advanced codec support
+ 
+ ---
+ 
+ This integration plan provides a comprehensive overview of how the enhanced features work together to create a cohesive, advanced viewing experience across devices. 
```

---



I'll explore the project structure first to get a better understanding of what we're working with.

---

<details>
            <summary>Listed current directory â€¢ **13** results</summary>
        
| Name |
|-------|
| ğŸ“ `.git` |
| ğŸ“ `docs` |
| ğŸ“„ `2-handoff.md` |
| ğŸ“„ `README.md` |
| ğŸ“„ `package.json` |
| ğŸ“„ `dev.js` |
| ğŸ“„ `build.js` |
| ğŸ“ `mobile-app` |
| ğŸ“ `tv-app` |
| ğŸ“ `backend` |
| ğŸ“ `.cursor` |
| ğŸ“„ `.cursorindexingignore` |
| ğŸ“ `.specstory` |

</details>

---

Let's check the README file first to understand the project better.

---

Read file: README.md

---

Now let's look at the package.json file to understand the dependencies and scripts:

---

Read file: package.json

---

Let's also look at the structure of the main components (tv-app, mobile-app, and backend):

---

<details>
            <summary>Listed directory tv-app â€¢ **4** results</summary>
        
| Name |
|-------|
| ğŸ“„ `package.json` |
| ğŸ“„ `webpack.config.js` |
| ğŸ“ `src` |
| ğŸ“ `public` |

</details>

---

<details>
            <summary>Listed directory tv-app/src â€¢ **3** results</summary>
        
| Name |
|-------|
| ğŸ“ `components` |
| ğŸ“ `styles` |
| ğŸ“„ `index.js` |

</details>

---

<details>
            <summary>Listed directory mobile-app â€¢ **4** results</summary>
        
| Name |
|-------|
| ğŸ“„ `package.json` |
| ğŸ“„ `webpack.config.js` |
| ğŸ“ `public` |
| ğŸ“ `src` |

</details>

---

<details>
            <summary>Listed directory mobile-app/src â€¢ **4** results</summary>
        
| Name |
|-------|
| ğŸ“ `components` |
| ğŸ“„ `index.js` |
| ğŸ“„ `service-worker.js` |
| ğŸ“ `styles` |

</details>

---

<details>
            <summary>Listed directory backend â€¢ **2** results</summary>
        
| Name |
|-------|
| ğŸ“„ `package.json` |
| ğŸ“ `src` |

</details>

---

<details>
            <summary>Listed directory backend/src â€¢ **2** results</summary>
        
| Name |
|-------|
| ğŸ“ `services` |
| ğŸ“„ `index.js` |

</details>

---

Now that I have a better understanding of the project structure, let's see if any of the mentioned enhanced features have already been implemented. I'll check for the ContentRecognitionService, SceneAnalysisService, and other mentioned services:

---

<details>
            <summary>Grep search for "ContentRecognitionService" â€¢ **4** files</summary>
        
| File | Line | Match |
|------|------|-------|
| `file:///d%3A/TV-App/docs/enhanced-features-integration.md` | L10 | `1. `ContentRecognitionService.js` in the backend analyzes dialogue text from the subtitle stream` |
| `file:///d%3A/TV-App/docs/enhanced-features-integration.md` | L20 | `Audio â†’ Whisper â†’ TranscribedText â†’ ContentRecognitionService â†’ TMDB API â†’ ContentMetadata` |
| `file:///d%3A/TV-App/backend/src/services/ContentRecognitionService.js` | L5 | `class ContentRecognitionService {` |
| `file:///d%3A/TV-App/backend/src/services/ContentRecognitionService.js` | L189 | `module.exports = ContentRecognitionService;` |
| `file:///d%3A/TV-App/.specstory/history/2025-05-17_05-02-continuing-handoff-documentation.md` | L450 | `// In backend/services/contentRecognitionService.js` |
| `file:///d%3A/TV-App/.specstory/history/2025-05-17_04-18-intelligent-viewing-experience-enhancements.md` | L224 | `2. Add a new `ContentRecognitionService.js` to the backend:` |
| `file:///d%3A/TV-App/.specstory/history/2025-05-17_04-18-intelligent-viewing-experience-enhancements.md` | L235 | `+ class ContentRecognitionService {` |
| `file:///d%3A/TV-App/.specstory/history/2025-05-17_04-18-intelligent-viewing-experience-enhancements.md` | L419 | `+ module.exports = ContentRecognitionService;` |
| `file:///d%3A/TV-App/.specstory/history/2025-05-17_04-18-intelligent-viewing-experience-enhancements.md` | L3925 | `+ 1. `ContentRecognitionService.js` in the backend analyzes dialogue text from the subtitle stream` |
| `file:///d%3A/TV-App/.specstory/history/2025-05-17_04-18-intelligent-viewing-experience-enhancements.md` | L3935 | `+ Audio â†’ Whisper â†’ TranscribedText â†’ ContentRecognitionService â†’ TMDB API â†’ ContentMetadata` |

</details>

---

Let's now check if the SceneAnalysisService exists:

---

<details>
            <summary>Grep search for "SceneAnalysisService" â€¢ **4** files</summary>
        
| File | Line | Match |
|------|------|-------|
| `file:///d%3A/TV-App/docs/enhanced-features-integration.md` | L27 | `1. `SceneAnalysisService.js` captures frames from the video at regular intervals` |
| `file:///d%3A/TV-App/docs/enhanced-features-integration.md` | L35 | `VideoFrames â†’ SceneAnalysisService â†’ GPT-4 Vision â†’ SceneContext â†’ Enhanced QA` |
| `file:///d%3A/TV-App/backend/src/services/SceneAnalysisService.js` | L5 | `class SceneAnalysisService {` |
| `file:///d%3A/TV-App/backend/src/services/SceneAnalysisService.js` | L180 | `module.exports = SceneAnalysisService;` |
| `file:///d%3A/TV-App/.specstory/history/2025-05-17_05-02-continuing-handoff-documentation.md` | L466 | `// In backend/services/sceneAnalysisService.js` |
| `file:///d%3A/TV-App/.specstory/history/2025-05-17_04-18-intelligent-viewing-experience-enhancements.md` | L436 | `+ class SceneAnalysisService {` |
| `file:///d%3A/TV-App/.specstory/history/2025-05-17_04-18-intelligent-viewing-experience-enhancements.md` | L611 | `+ module.exports = SceneAnalysisService;` |
| `file:///d%3A/TV-App/.specstory/history/2025-05-17_04-18-intelligent-viewing-experience-enhancements.md` | L3942 | `+ 1. `SceneAnalysisService.js` captures frames from the video at regular intervals` |
| `file:///d%3A/TV-App/.specstory/history/2025-05-17_04-18-intelligent-viewing-experience-enhancements.md` | L3950 | `+ VideoFrames â†’ SceneAnalysisService â†’ GPT-4 Vision â†’ SceneContext â†’ Enhanced QA` |

</details>

---

Now let's look at the RecommendationService:

---

<details>
            <summary>Grep search for "RecommendationService" â€¢ **3** files</summary>
        
| File | Line | Match |
|------|------|-------|
| `file:///d%3A/TV-App/docs/enhanced-features-integration.md` | L42 | `1. `RecommendationService.js` tracks user interactions with content` |
| `file:///d%3A/TV-App/docs/enhanced-features-integration.md` | L52 | `UserInteractions â†’ RecommendationService â†’ UserProfiles â†’ TMDB + GPT-4 â†’ Recommendations` |
| `file:///d%3A/TV-App/backend/src/services/RecommendationService.js` | L6 | `class RecommendationService {` |
| `file:///d%3A/TV-App/backend/src/services/RecommendationService.js` | L635 | `module.exports = RecommendationService;` |
| `file:///d%3A/TV-App/.specstory/history/2025-05-17_04-18-intelligent-viewing-experience-enhancements.md` | L629 | `+ class RecommendationService {` |
| `file:///d%3A/TV-App/.specstory/history/2025-05-17_04-18-intelligent-viewing-experience-enhancements.md` | L1258 | `+ module.exports = RecommendationService;` |
| `file:///d%3A/TV-App/.specstory/history/2025-05-17_04-18-intelligent-viewing-experience-enhancements.md` | L3957 | `+ 1. `RecommendationService.js` tracks user interactions with content` |
| `file:///d%3A/TV-App/.specstory/history/2025-05-17_04-18-intelligent-viewing-experience-enhancements.md` | L3967 | `+ UserInteractions â†’ RecommendationService â†’ UserProfiles â†’ TMDB + GPT-4 â†’ Recommendations` |

</details>

---

Let's check for the SharedViewingService for multi-device experience:

---

<details>
            <summary>Grep search for "SharedViewingService" â€¢ **3** files</summary>
        
| File | Line | Match |
|------|------|-------|
| `file:///d%3A/TV-App/docs/enhanced-features-integration.md` | L61 | `1. `SharedViewingService.js` manages viewing sessions` |
| `file:///d%3A/TV-App/backend/src/services/SharedViewingService.js` | L4 | `class SharedViewingService {` |
| `file:///d%3A/TV-App/backend/src/services/SharedViewingService.js` | L637 | `module.exports = SharedViewingService;` |
| `file:///d%3A/TV-App/.specstory/history/2025-05-17_04-18-intelligent-viewing-experience-enhancements.md` | L1274 | `+ class SharedViewingService {` |
| `file:///d%3A/TV-App/.specstory/history/2025-05-17_04-18-intelligent-viewing-experience-enhancements.md` | L1907 | `+ module.exports = SharedViewingService;` |
| `file:///d%3A/TV-App/.specstory/history/2025-05-17_04-18-intelligent-viewing-experience-enhancements.md` | L3976 | `+ 1. `SharedViewingService.js` manages viewing sessions` |

</details>

---

Let's check for MobileSaver.js:

---

<details>
            <summary>Grep search for "MobileSaver" â€¢ **3** files</summary>
        
| File | Line | Match |
|------|------|-------|
| `file:///d%3A/TV-App/mobile-app/src/components/MobileSaver.js` | L1 | `* MobileSaver.js` |
| `file:///d%3A/TV-App/mobile-app/src/components/MobileSaver.js` | L5 | `class MobileSaver {` |
| `file:///d%3A/TV-App/mobile-app/src/components/MobileSaver.js` | L321 | `export default MobileSaver;` |
| `file:///d%3A/TV-App/docs/enhanced-features-integration.md` | L94 | `1. `MobileSaver.js` component on mobile receives saved items` |
| `file:///d%3A/TV-App/.specstory/history/2025-05-17_04-18-intelligent-viewing-experience-enhancements.md` | L1920 | `+  * MobileSaver.js` |
| `file:///d%3A/TV-App/.specstory/history/2025-05-17_04-18-intelligent-viewing-experience-enhancements.md` | L1924 | `+ class MobileSaver {` |
| `file:///d%3A/TV-App/.specstory/history/2025-05-17_04-18-intelligent-viewing-experience-enhancements.md` | L2240 | `+ export default MobileSaver;` |
| `file:///d%3A/TV-App/.specstory/history/2025-05-17_04-18-intelligent-viewing-experience-enhancements.md` | L4009 | `+ 1. `MobileSaver.js` component on mobile receives saved items` |

</details>

---

Let's check for the OptimizedWhisperService:

---

<details>
            <summary>Grep search for "OptimizedWhisperService" â€¢ **3** files</summary>
        
| File | Line | Match |
|------|------|-------|
| `file:///d%3A/TV-App/docs/enhanced-features-integration.md` | L113 | `1. `OptimizedWhisperService.js` processes audio in small chunks` |
| `file:///d%3A/TV-App/backend/src/services/OptimizedWhisperService.js` | L17 | `class OptimizedWhisperService {` |
| `file:///d%3A/TV-App/backend/src/services/OptimizedWhisperService.js` | L548 | `module.exports = OptimizedWhisperService;` |
| `file:///d%3A/TV-App/.specstory/history/2025-05-17_04-18-intelligent-viewing-experience-enhancements.md` | L2269 | `+ class OptimizedWhisperService {` |
| `file:///d%3A/TV-App/.specstory/history/2025-05-17_04-18-intelligent-viewing-experience-enhancements.md` | L2800 | `+ module.exports = OptimizedWhisperService;` |
| `file:///d%3A/TV-App/.specstory/history/2025-05-17_04-18-intelligent-viewing-experience-enhancements.md` | L4028 | `+ 1. `OptimizedWhisperService.js` processes audio in small chunks` |

</details>

---

Let's check for WakeWordDetector.js:

---

<details>
            <summary>Grep search for "WakeWordDetector" â€¢ **4** files</summary>
        
| File | Line | Match |
|------|------|-------|
| `file:///d%3A/TV-App/mobile-app/src/components/WakeWordDetector.js` | L1 | `* WakeWordDetector.js` |
| `file:///d%3A/TV-App/mobile-app/src/components/WakeWordDetector.js` | L5 | `class WakeWordDetector {` |
| `file:///d%3A/TV-App/mobile-app/src/components/WakeWordDetector.js` | L420 | `export default WakeWordDetector;` |
| `file:///d%3A/TV-App/docs/enhanced-features-integration.md` | L129 | `1. `WakeWordDetector.js` runs entirely on the mobile device` |
| `file:///d%3A/TV-App/.specstory/history/2025-05-17_05-02-continuing-handoff-documentation.md` | L576 | `// In mobile-app/voice/wakeWordDetector.js` |
| `file:///d%3A/TV-App/.specstory/history/2025-05-17_05-02-continuing-handoff-documentation.md` | L577 | `class WakeWordDetector {` |
| `file:///d%3A/TV-App/.specstory/history/2025-05-17_04-18-intelligent-viewing-experience-enhancements.md` | L2813 | `+  * WakeWordDetector.js` |
| `file:///d%3A/TV-App/.specstory/history/2025-05-17_04-18-intelligent-viewing-experience-enhancements.md` | L2817 | `+ class WakeWordDetector {` |
| `file:///d%3A/TV-App/.specstory/history/2025-05-17_04-18-intelligent-viewing-experience-enhancements.md` | L3232 | `+ export default WakeWordDetector;` |
| `file:///d%3A/TV-App/.specstory/history/2025-05-17_04-18-intelligent-viewing-experience-enhancements.md` | L4044 | `+ 1. `WakeWordDetector.js` runs entirely on the mobile device` |

</details>

---

Let's check for AdaptiveStreamingManager.js:

---

<details>
            <summary>Grep search for "AdaptiveStreamingManager" â€¢ **3** files</summary>
        
| File | Line | Match |
|------|------|-------|
| `file:///d%3A/TV-App/tv-app/src/components/AdaptiveStreamingManager.js` | L1 | `* AdaptiveStreamingManager.js` |
| `file:///d%3A/TV-App/tv-app/src/components/AdaptiveStreamingManager.js` | L5 | `class AdaptiveStreamingManager {` |
| `file:///d%3A/TV-App/tv-app/src/components/AdaptiveStreamingManager.js` | L88 | `console.log('AdaptiveStreamingManager initialized');` |
| `file:///d%3A/TV-App/tv-app/src/components/AdaptiveStreamingManager.js` | L580 | `export default AdaptiveStreamingManager;` |
| `file:///d%3A/TV-App/docs/enhanced-features-integration.md` | L145 | `1. `AdaptiveStreamingManager.js` integrates with the video player` |
| `file:///d%3A/TV-App/.specstory/history/2025-05-17_04-18-intelligent-viewing-experience-enhancements.md` | L3245 | `+  * AdaptiveStreamingManager.js` |
| `file:///d%3A/TV-App/.specstory/history/2025-05-17_04-18-intelligent-viewing-experience-enhancements.md` | L3249 | `+ class AdaptiveStreamingManager {` |
| `file:///d%3A/TV-App/.specstory/history/2025-05-17_04-18-intelligent-viewing-experience-enhancements.md` | L3332 | `+     console.log('AdaptiveStreamingManager initialized');` |
| `file:///d%3A/TV-App/.specstory/history/2025-05-17_04-18-intelligent-viewing-experience-enhancements.md` | L3824 | `+ export default AdaptiveStreamingManager;` |
| `file:///d%3A/TV-App/.specstory/history/2025-05-17_04-18-intelligent-viewing-experience-enhancements.md` | L4060 | `+ 1. `AdaptiveStreamingManager.js` integrates with the video player` |

</details>

---

Let's examine the integration document that contains details on these enhanced features:

---

Read file: docs/enhanced-features-integration.md

---

Now, let's check the implementation files for some of these services to get a better understanding of the enhanced features. Let's start with ContentRecognitionService:

---

Read file: backend/src/services/ContentRecognitionService.js

---

Now let's look at SceneAnalysisService:

---

Read file: backend/src/services/SceneAnalysisService.js

---

Let's check one of the technical showcase implementations, like the OptimizedWhisperService:

---

Read file: backend/src/services/OptimizedWhisperService.js

---

Let's check one more - the WakeWordDetector on the mobile app side:

---

Read file: mobile-app/src/components/WakeWordDetector.js

---

Based on my exploration, here's a summary of the enhanced features implemented for the MemoryStream TV application:

1. **Enhanced Intelligence Features**:
   - ContentRecognitionService: Identifies TV shows/movies based on dialogue using TMDB API
   - SceneAnalysisService: Uses OpenAI's Vision model to understand on-screen content
   - RecommendationService: Provides personalized content suggestions based on user history

2. **Multi-device Experience**:
   - SharedViewingService: Enables synchronized playback across devices with join codes
   - Collaborative Q&A: Allows multiple users to ask/answer questions about content
   - MobileSaver: Implements "send to mobile" feature for saving timestamps, links, and notes

3. **Technical Showcases**:
   - OptimizedWhisperService: Uses batch processing for near real-time subtitle generation
   - WakeWordDetector: Provides local speech recognition with "hey memory" wake word
   - AdaptiveStreamingManager: Adjusts video quality based on network conditions

These implementations showcase innovative features that transform passive TV watching into an interactive, intelligent experience. The architecture follows a modular approach with clear boundaries between components, making it maintainable and extensible.

The services are well-documented with detailed JSDoc comments, proper error handling, and optimizations like caching for improved performance. The code also demonstrates good practices like resource cleanup and batching operations for API efficiency.

---

_**User**_

whats next?

---

